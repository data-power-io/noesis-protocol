// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: datapower/noesis/v1/execution.proto

package datapower.noesis.v1;

/**
 * <pre>
 * BatchReconciliationJobSpec defines the main batch transformation job
 * </pre>
 *
 * Protobuf type {@code datapower.noesis.v1.BatchReconciliationJobSpec}
 */
public final class BatchReconciliationJobSpec extends
    com.google.protobuf.GeneratedMessageV3 implements
    // @@protoc_insertion_point(message_implements:datapower.noesis.v1.BatchReconciliationJobSpec)
    BatchReconciliationJobSpecOrBuilder {
private static final long serialVersionUID = 0L;
  // Use BatchReconciliationJobSpec.newBuilder() to construct.
  private BatchReconciliationJobSpec(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
    super(builder);
  }
  private BatchReconciliationJobSpec() {
    jobName_ = "";
    sinkTopic_ = "";
    flinkSql_ = "";
    sourceTables_ =
        com.google.protobuf.LazyStringArrayList.emptyList();
    primaryKey_ = "";
  }

  @java.lang.Override
  @SuppressWarnings({"unused"})
  protected java.lang.Object newInstance(
      UnusedPrivateParameter unused) {
    return new BatchReconciliationJobSpec();
  }

  public static final com.google.protobuf.Descriptors.Descriptor
      getDescriptor() {
    return datapower.noesis.v1.Execution.internal_static_datapower_noesis_v1_BatchReconciliationJobSpec_descriptor;
  }

  @java.lang.Override
  protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internalGetFieldAccessorTable() {
    return datapower.noesis.v1.Execution.internal_static_datapower_noesis_v1_BatchReconciliationJobSpec_fieldAccessorTable
        .ensureFieldAccessorsInitialized(
            datapower.noesis.v1.BatchReconciliationJobSpec.class, datapower.noesis.v1.BatchReconciliationJobSpec.Builder.class);
  }

  public static final int JOB_NAME_FIELD_NUMBER = 1;
  @SuppressWarnings("serial")
  private volatile java.lang.Object jobName_ = "";
  /**
   * <pre>
   * Unique job name (e.g., "customer-360-view_batch_reconciliation")
   * </pre>
   *
   * <code>string job_name = 1 [json_name = "jobName"];</code>
   * @return The jobName.
   */
  @java.lang.Override
  public java.lang.String getJobName() {
    java.lang.Object ref = jobName_;
    if (ref instanceof java.lang.String) {
      return (java.lang.String) ref;
    } else {
      com.google.protobuf.ByteString bs = 
          (com.google.protobuf.ByteString) ref;
      java.lang.String s = bs.toStringUtf8();
      jobName_ = s;
      return s;
    }
  }
  /**
   * <pre>
   * Unique job name (e.g., "customer-360-view_batch_reconciliation")
   * </pre>
   *
   * <code>string job_name = 1 [json_name = "jobName"];</code>
   * @return The bytes for jobName.
   */
  @java.lang.Override
  public com.google.protobuf.ByteString
      getJobNameBytes() {
    java.lang.Object ref = jobName_;
    if (ref instanceof java.lang.String) {
      com.google.protobuf.ByteString b = 
          com.google.protobuf.ByteString.copyFromUtf8(
              (java.lang.String) ref);
      jobName_ = b;
      return b;
    } else {
      return (com.google.protobuf.ByteString) ref;
    }
  }

  public static final int SINK_TOPIC_FIELD_NUMBER = 2;
  @SuppressWarnings("serial")
  private volatile java.lang.Object sinkTopic_ = "";
  /**
   * <pre>
   * Sink topic where full-state events are written
   * </pre>
   *
   * <code>string sink_topic = 2 [json_name = "sinkTopic"];</code>
   * @return The sinkTopic.
   */
  @java.lang.Override
  public java.lang.String getSinkTopic() {
    java.lang.Object ref = sinkTopic_;
    if (ref instanceof java.lang.String) {
      return (java.lang.String) ref;
    } else {
      com.google.protobuf.ByteString bs = 
          (com.google.protobuf.ByteString) ref;
      java.lang.String s = bs.toStringUtf8();
      sinkTopic_ = s;
      return s;
    }
  }
  /**
   * <pre>
   * Sink topic where full-state events are written
   * </pre>
   *
   * <code>string sink_topic = 2 [json_name = "sinkTopic"];</code>
   * @return The bytes for sinkTopic.
   */
  @java.lang.Override
  public com.google.protobuf.ByteString
      getSinkTopicBytes() {
    java.lang.Object ref = sinkTopic_;
    if (ref instanceof java.lang.String) {
      com.google.protobuf.ByteString b = 
          com.google.protobuf.ByteString.copyFromUtf8(
              (java.lang.String) ref);
      sinkTopic_ = b;
      return b;
    } else {
      return (com.google.protobuf.ByteString) ref;
    }
  }

  public static final int FLINK_SQL_FIELD_NUMBER = 3;
  @SuppressWarnings("serial")
  private volatile java.lang.Object flinkSql_ = "";
  /**
   * <pre>
   * Generated Flink SQL for batch reconciliation
   * This wraps the user's original SQL query
   * </pre>
   *
   * <code>string flink_sql = 3 [json_name = "flinkSql"];</code>
   * @return The flinkSql.
   */
  @java.lang.Override
  public java.lang.String getFlinkSql() {
    java.lang.Object ref = flinkSql_;
    if (ref instanceof java.lang.String) {
      return (java.lang.String) ref;
    } else {
      com.google.protobuf.ByteString bs = 
          (com.google.protobuf.ByteString) ref;
      java.lang.String s = bs.toStringUtf8();
      flinkSql_ = s;
      return s;
    }
  }
  /**
   * <pre>
   * Generated Flink SQL for batch reconciliation
   * This wraps the user's original SQL query
   * </pre>
   *
   * <code>string flink_sql = 3 [json_name = "flinkSql"];</code>
   * @return The bytes for flinkSql.
   */
  @java.lang.Override
  public com.google.protobuf.ByteString
      getFlinkSqlBytes() {
    java.lang.Object ref = flinkSql_;
    if (ref instanceof java.lang.String) {
      com.google.protobuf.ByteString b = 
          com.google.protobuf.ByteString.copyFromUtf8(
              (java.lang.String) ref);
      flinkSql_ = b;
      return b;
    } else {
      return (com.google.protobuf.ByteString) ref;
    }
  }

  public static final int SOURCE_TABLES_FIELD_NUMBER = 4;
  @SuppressWarnings("serial")
  private com.google.protobuf.LazyStringArrayList sourceTables_ =
      com.google.protobuf.LazyStringArrayList.emptyList();
  /**
   * <pre>
   * Source Iceberg tables referenced in the job
   * </pre>
   *
   * <code>repeated string source_tables = 4 [json_name = "sourceTables"];</code>
   * @return A list containing the sourceTables.
   */
  public com.google.protobuf.ProtocolStringList
      getSourceTablesList() {
    return sourceTables_;
  }
  /**
   * <pre>
   * Source Iceberg tables referenced in the job
   * </pre>
   *
   * <code>repeated string source_tables = 4 [json_name = "sourceTables"];</code>
   * @return The count of sourceTables.
   */
  public int getSourceTablesCount() {
    return sourceTables_.size();
  }
  /**
   * <pre>
   * Source Iceberg tables referenced in the job
   * </pre>
   *
   * <code>repeated string source_tables = 4 [json_name = "sourceTables"];</code>
   * @param index The index of the element to return.
   * @return The sourceTables at the given index.
   */
  public java.lang.String getSourceTables(int index) {
    return sourceTables_.get(index);
  }
  /**
   * <pre>
   * Source Iceberg tables referenced in the job
   * </pre>
   *
   * <code>repeated string source_tables = 4 [json_name = "sourceTables"];</code>
   * @param index The index of the value to return.
   * @return The bytes of the sourceTables at the given index.
   */
  public com.google.protobuf.ByteString
      getSourceTablesBytes(int index) {
    return sourceTables_.getByteString(index);
  }

  public static final int PRIMARY_KEY_FIELD_NUMBER = 5;
  @SuppressWarnings("serial")
  private volatile java.lang.Object primaryKey_ = "";
  /**
   * <pre>
   * Primary key for output records
   * </pre>
   *
   * <code>string primary_key = 5 [json_name = "primaryKey"];</code>
   * @return The primaryKey.
   */
  @java.lang.Override
  public java.lang.String getPrimaryKey() {
    java.lang.Object ref = primaryKey_;
    if (ref instanceof java.lang.String) {
      return (java.lang.String) ref;
    } else {
      com.google.protobuf.ByteString bs = 
          (com.google.protobuf.ByteString) ref;
      java.lang.String s = bs.toStringUtf8();
      primaryKey_ = s;
      return s;
    }
  }
  /**
   * <pre>
   * Primary key for output records
   * </pre>
   *
   * <code>string primary_key = 5 [json_name = "primaryKey"];</code>
   * @return The bytes for primaryKey.
   */
  @java.lang.Override
  public com.google.protobuf.ByteString
      getPrimaryKeyBytes() {
    java.lang.Object ref = primaryKey_;
    if (ref instanceof java.lang.String) {
      com.google.protobuf.ByteString b = 
          com.google.protobuf.ByteString.copyFromUtf8(
              (java.lang.String) ref);
      primaryKey_ = b;
      return b;
    } else {
      return (com.google.protobuf.ByteString) ref;
    }
  }

  public static final int PARALLELISM_FIELD_NUMBER = 6;
  private int parallelism_ = 0;
  /**
   * <pre>
   * Parallelism for the batch job
   * </pre>
   *
   * <code>int32 parallelism = 6 [json_name = "parallelism"];</code>
   * @return The parallelism.
   */
  @java.lang.Override
  public int getParallelism() {
    return parallelism_;
  }

  public static final int EXPECTED_RUNTIME_MS_FIELD_NUMBER = 7;
  private long expectedRuntimeMs_ = 0L;
  /**
   * <pre>
   * Expected runtime (for monitoring)
   * </pre>
   *
   * <code>int64 expected_runtime_ms = 7 [json_name = "expectedRuntimeMs"];</code>
   * @return The expectedRuntimeMs.
   */
  @java.lang.Override
  public long getExpectedRuntimeMs() {
    return expectedRuntimeMs_;
  }

  private byte memoizedIsInitialized = -1;
  @java.lang.Override
  public final boolean isInitialized() {
    byte isInitialized = memoizedIsInitialized;
    if (isInitialized == 1) return true;
    if (isInitialized == 0) return false;

    memoizedIsInitialized = 1;
    return true;
  }

  @java.lang.Override
  public void writeTo(com.google.protobuf.CodedOutputStream output)
                      throws java.io.IOException {
    if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(jobName_)) {
      com.google.protobuf.GeneratedMessageV3.writeString(output, 1, jobName_);
    }
    if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(sinkTopic_)) {
      com.google.protobuf.GeneratedMessageV3.writeString(output, 2, sinkTopic_);
    }
    if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(flinkSql_)) {
      com.google.protobuf.GeneratedMessageV3.writeString(output, 3, flinkSql_);
    }
    for (int i = 0; i < sourceTables_.size(); i++) {
      com.google.protobuf.GeneratedMessageV3.writeString(output, 4, sourceTables_.getRaw(i));
    }
    if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(primaryKey_)) {
      com.google.protobuf.GeneratedMessageV3.writeString(output, 5, primaryKey_);
    }
    if (parallelism_ != 0) {
      output.writeInt32(6, parallelism_);
    }
    if (expectedRuntimeMs_ != 0L) {
      output.writeInt64(7, expectedRuntimeMs_);
    }
    getUnknownFields().writeTo(output);
  }

  @java.lang.Override
  public int getSerializedSize() {
    int size = memoizedSize;
    if (size != -1) return size;

    size = 0;
    if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(jobName_)) {
      size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, jobName_);
    }
    if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(sinkTopic_)) {
      size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, sinkTopic_);
    }
    if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(flinkSql_)) {
      size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, flinkSql_);
    }
    {
      int dataSize = 0;
      for (int i = 0; i < sourceTables_.size(); i++) {
        dataSize += computeStringSizeNoTag(sourceTables_.getRaw(i));
      }
      size += dataSize;
      size += 1 * getSourceTablesList().size();
    }
    if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(primaryKey_)) {
      size += com.google.protobuf.GeneratedMessageV3.computeStringSize(5, primaryKey_);
    }
    if (parallelism_ != 0) {
      size += com.google.protobuf.CodedOutputStream
        .computeInt32Size(6, parallelism_);
    }
    if (expectedRuntimeMs_ != 0L) {
      size += com.google.protobuf.CodedOutputStream
        .computeInt64Size(7, expectedRuntimeMs_);
    }
    size += getUnknownFields().getSerializedSize();
    memoizedSize = size;
    return size;
  }

  @java.lang.Override
  public boolean equals(final java.lang.Object obj) {
    if (obj == this) {
     return true;
    }
    if (!(obj instanceof datapower.noesis.v1.BatchReconciliationJobSpec)) {
      return super.equals(obj);
    }
    datapower.noesis.v1.BatchReconciliationJobSpec other = (datapower.noesis.v1.BatchReconciliationJobSpec) obj;

    if (!getJobName()
        .equals(other.getJobName())) return false;
    if (!getSinkTopic()
        .equals(other.getSinkTopic())) return false;
    if (!getFlinkSql()
        .equals(other.getFlinkSql())) return false;
    if (!getSourceTablesList()
        .equals(other.getSourceTablesList())) return false;
    if (!getPrimaryKey()
        .equals(other.getPrimaryKey())) return false;
    if (getParallelism()
        != other.getParallelism()) return false;
    if (getExpectedRuntimeMs()
        != other.getExpectedRuntimeMs()) return false;
    if (!getUnknownFields().equals(other.getUnknownFields())) return false;
    return true;
  }

  @java.lang.Override
  public int hashCode() {
    if (memoizedHashCode != 0) {
      return memoizedHashCode;
    }
    int hash = 41;
    hash = (19 * hash) + getDescriptor().hashCode();
    hash = (37 * hash) + JOB_NAME_FIELD_NUMBER;
    hash = (53 * hash) + getJobName().hashCode();
    hash = (37 * hash) + SINK_TOPIC_FIELD_NUMBER;
    hash = (53 * hash) + getSinkTopic().hashCode();
    hash = (37 * hash) + FLINK_SQL_FIELD_NUMBER;
    hash = (53 * hash) + getFlinkSql().hashCode();
    if (getSourceTablesCount() > 0) {
      hash = (37 * hash) + SOURCE_TABLES_FIELD_NUMBER;
      hash = (53 * hash) + getSourceTablesList().hashCode();
    }
    hash = (37 * hash) + PRIMARY_KEY_FIELD_NUMBER;
    hash = (53 * hash) + getPrimaryKey().hashCode();
    hash = (37 * hash) + PARALLELISM_FIELD_NUMBER;
    hash = (53 * hash) + getParallelism();
    hash = (37 * hash) + EXPECTED_RUNTIME_MS_FIELD_NUMBER;
    hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
        getExpectedRuntimeMs());
    hash = (29 * hash) + getUnknownFields().hashCode();
    memoizedHashCode = hash;
    return hash;
  }

  public static datapower.noesis.v1.BatchReconciliationJobSpec parseFrom(
      java.nio.ByteBuffer data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static datapower.noesis.v1.BatchReconciliationJobSpec parseFrom(
      java.nio.ByteBuffer data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static datapower.noesis.v1.BatchReconciliationJobSpec parseFrom(
      com.google.protobuf.ByteString data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static datapower.noesis.v1.BatchReconciliationJobSpec parseFrom(
      com.google.protobuf.ByteString data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static datapower.noesis.v1.BatchReconciliationJobSpec parseFrom(byte[] data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static datapower.noesis.v1.BatchReconciliationJobSpec parseFrom(
      byte[] data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static datapower.noesis.v1.BatchReconciliationJobSpec parseFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input);
  }
  public static datapower.noesis.v1.BatchReconciliationJobSpec parseFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input, extensionRegistry);
  }

  public static datapower.noesis.v1.BatchReconciliationJobSpec parseDelimitedFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseDelimitedWithIOException(PARSER, input);
  }

  public static datapower.noesis.v1.BatchReconciliationJobSpec parseDelimitedFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
  }
  public static datapower.noesis.v1.BatchReconciliationJobSpec parseFrom(
      com.google.protobuf.CodedInputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input);
  }
  public static datapower.noesis.v1.BatchReconciliationJobSpec parseFrom(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input, extensionRegistry);
  }

  @java.lang.Override
  public Builder newBuilderForType() { return newBuilder(); }
  public static Builder newBuilder() {
    return DEFAULT_INSTANCE.toBuilder();
  }
  public static Builder newBuilder(datapower.noesis.v1.BatchReconciliationJobSpec prototype) {
    return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
  }
  @java.lang.Override
  public Builder toBuilder() {
    return this == DEFAULT_INSTANCE
        ? new Builder() : new Builder().mergeFrom(this);
  }

  @java.lang.Override
  protected Builder newBuilderForType(
      com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
    Builder builder = new Builder(parent);
    return builder;
  }
  /**
   * <pre>
   * BatchReconciliationJobSpec defines the main batch transformation job
   * </pre>
   *
   * Protobuf type {@code datapower.noesis.v1.BatchReconciliationJobSpec}
   */
  public static final class Builder extends
      com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
      // @@protoc_insertion_point(builder_implements:datapower.noesis.v1.BatchReconciliationJobSpec)
      datapower.noesis.v1.BatchReconciliationJobSpecOrBuilder {
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return datapower.noesis.v1.Execution.internal_static_datapower_noesis_v1_BatchReconciliationJobSpec_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return datapower.noesis.v1.Execution.internal_static_datapower_noesis_v1_BatchReconciliationJobSpec_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              datapower.noesis.v1.BatchReconciliationJobSpec.class, datapower.noesis.v1.BatchReconciliationJobSpec.Builder.class);
    }

    // Construct using datapower.noesis.v1.BatchReconciliationJobSpec.newBuilder()
    private Builder() {

    }

    private Builder(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      super(parent);

    }
    @java.lang.Override
    public Builder clear() {
      super.clear();
      bitField0_ = 0;
      jobName_ = "";
      sinkTopic_ = "";
      flinkSql_ = "";
      sourceTables_ =
          com.google.protobuf.LazyStringArrayList.emptyList();
      primaryKey_ = "";
      parallelism_ = 0;
      expectedRuntimeMs_ = 0L;
      return this;
    }

    @java.lang.Override
    public com.google.protobuf.Descriptors.Descriptor
        getDescriptorForType() {
      return datapower.noesis.v1.Execution.internal_static_datapower_noesis_v1_BatchReconciliationJobSpec_descriptor;
    }

    @java.lang.Override
    public datapower.noesis.v1.BatchReconciliationJobSpec getDefaultInstanceForType() {
      return datapower.noesis.v1.BatchReconciliationJobSpec.getDefaultInstance();
    }

    @java.lang.Override
    public datapower.noesis.v1.BatchReconciliationJobSpec build() {
      datapower.noesis.v1.BatchReconciliationJobSpec result = buildPartial();
      if (!result.isInitialized()) {
        throw newUninitializedMessageException(result);
      }
      return result;
    }

    @java.lang.Override
    public datapower.noesis.v1.BatchReconciliationJobSpec buildPartial() {
      datapower.noesis.v1.BatchReconciliationJobSpec result = new datapower.noesis.v1.BatchReconciliationJobSpec(this);
      if (bitField0_ != 0) { buildPartial0(result); }
      onBuilt();
      return result;
    }

    private void buildPartial0(datapower.noesis.v1.BatchReconciliationJobSpec result) {
      int from_bitField0_ = bitField0_;
      if (((from_bitField0_ & 0x00000001) != 0)) {
        result.jobName_ = jobName_;
      }
      if (((from_bitField0_ & 0x00000002) != 0)) {
        result.sinkTopic_ = sinkTopic_;
      }
      if (((from_bitField0_ & 0x00000004) != 0)) {
        result.flinkSql_ = flinkSql_;
      }
      if (((from_bitField0_ & 0x00000008) != 0)) {
        sourceTables_.makeImmutable();
        result.sourceTables_ = sourceTables_;
      }
      if (((from_bitField0_ & 0x00000010) != 0)) {
        result.primaryKey_ = primaryKey_;
      }
      if (((from_bitField0_ & 0x00000020) != 0)) {
        result.parallelism_ = parallelism_;
      }
      if (((from_bitField0_ & 0x00000040) != 0)) {
        result.expectedRuntimeMs_ = expectedRuntimeMs_;
      }
    }

    @java.lang.Override
    public Builder clone() {
      return super.clone();
    }
    @java.lang.Override
    public Builder setField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        java.lang.Object value) {
      return super.setField(field, value);
    }
    @java.lang.Override
    public Builder clearField(
        com.google.protobuf.Descriptors.FieldDescriptor field) {
      return super.clearField(field);
    }
    @java.lang.Override
    public Builder clearOneof(
        com.google.protobuf.Descriptors.OneofDescriptor oneof) {
      return super.clearOneof(oneof);
    }
    @java.lang.Override
    public Builder setRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        int index, java.lang.Object value) {
      return super.setRepeatedField(field, index, value);
    }
    @java.lang.Override
    public Builder addRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        java.lang.Object value) {
      return super.addRepeatedField(field, value);
    }
    @java.lang.Override
    public Builder mergeFrom(com.google.protobuf.Message other) {
      if (other instanceof datapower.noesis.v1.BatchReconciliationJobSpec) {
        return mergeFrom((datapower.noesis.v1.BatchReconciliationJobSpec)other);
      } else {
        super.mergeFrom(other);
        return this;
      }
    }

    public Builder mergeFrom(datapower.noesis.v1.BatchReconciliationJobSpec other) {
      if (other == datapower.noesis.v1.BatchReconciliationJobSpec.getDefaultInstance()) return this;
      if (!other.getJobName().isEmpty()) {
        jobName_ = other.jobName_;
        bitField0_ |= 0x00000001;
        onChanged();
      }
      if (!other.getSinkTopic().isEmpty()) {
        sinkTopic_ = other.sinkTopic_;
        bitField0_ |= 0x00000002;
        onChanged();
      }
      if (!other.getFlinkSql().isEmpty()) {
        flinkSql_ = other.flinkSql_;
        bitField0_ |= 0x00000004;
        onChanged();
      }
      if (!other.sourceTables_.isEmpty()) {
        if (sourceTables_.isEmpty()) {
          sourceTables_ = other.sourceTables_;
          bitField0_ |= 0x00000008;
        } else {
          ensureSourceTablesIsMutable();
          sourceTables_.addAll(other.sourceTables_);
        }
        onChanged();
      }
      if (!other.getPrimaryKey().isEmpty()) {
        primaryKey_ = other.primaryKey_;
        bitField0_ |= 0x00000010;
        onChanged();
      }
      if (other.getParallelism() != 0) {
        setParallelism(other.getParallelism());
      }
      if (other.getExpectedRuntimeMs() != 0L) {
        setExpectedRuntimeMs(other.getExpectedRuntimeMs());
      }
      this.mergeUnknownFields(other.getUnknownFields());
      onChanged();
      return this;
    }

    @java.lang.Override
    public final boolean isInitialized() {
      return true;
    }

    @java.lang.Override
    public Builder mergeFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              jobName_ = input.readStringRequireUtf8();
              bitField0_ |= 0x00000001;
              break;
            } // case 10
            case 18: {
              sinkTopic_ = input.readStringRequireUtf8();
              bitField0_ |= 0x00000002;
              break;
            } // case 18
            case 26: {
              flinkSql_ = input.readStringRequireUtf8();
              bitField0_ |= 0x00000004;
              break;
            } // case 26
            case 34: {
              java.lang.String s = input.readStringRequireUtf8();
              ensureSourceTablesIsMutable();
              sourceTables_.add(s);
              break;
            } // case 34
            case 42: {
              primaryKey_ = input.readStringRequireUtf8();
              bitField0_ |= 0x00000010;
              break;
            } // case 42
            case 48: {
              parallelism_ = input.readInt32();
              bitField0_ |= 0x00000020;
              break;
            } // case 48
            case 56: {
              expectedRuntimeMs_ = input.readInt64();
              bitField0_ |= 0x00000040;
              break;
            } // case 56
            default: {
              if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                done = true; // was an endgroup tag
              }
              break;
            } // default:
          } // switch (tag)
        } // while (!done)
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.unwrapIOException();
      } finally {
        onChanged();
      } // finally
      return this;
    }
    private int bitField0_;

    private java.lang.Object jobName_ = "";
    /**
     * <pre>
     * Unique job name (e.g., "customer-360-view_batch_reconciliation")
     * </pre>
     *
     * <code>string job_name = 1 [json_name = "jobName"];</code>
     * @return The jobName.
     */
    public java.lang.String getJobName() {
      java.lang.Object ref = jobName_;
      if (!(ref instanceof java.lang.String)) {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        jobName_ = s;
        return s;
      } else {
        return (java.lang.String) ref;
      }
    }
    /**
     * <pre>
     * Unique job name (e.g., "customer-360-view_batch_reconciliation")
     * </pre>
     *
     * <code>string job_name = 1 [json_name = "jobName"];</code>
     * @return The bytes for jobName.
     */
    public com.google.protobuf.ByteString
        getJobNameBytes() {
      java.lang.Object ref = jobName_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        jobName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    /**
     * <pre>
     * Unique job name (e.g., "customer-360-view_batch_reconciliation")
     * </pre>
     *
     * <code>string job_name = 1 [json_name = "jobName"];</code>
     * @param value The jobName to set.
     * @return This builder for chaining.
     */
    public Builder setJobName(
        java.lang.String value) {
      if (value == null) { throw new NullPointerException(); }
      jobName_ = value;
      bitField0_ |= 0x00000001;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Unique job name (e.g., "customer-360-view_batch_reconciliation")
     * </pre>
     *
     * <code>string job_name = 1 [json_name = "jobName"];</code>
     * @return This builder for chaining.
     */
    public Builder clearJobName() {
      jobName_ = getDefaultInstance().getJobName();
      bitField0_ = (bitField0_ & ~0x00000001);
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Unique job name (e.g., "customer-360-view_batch_reconciliation")
     * </pre>
     *
     * <code>string job_name = 1 [json_name = "jobName"];</code>
     * @param value The bytes for jobName to set.
     * @return This builder for chaining.
     */
    public Builder setJobNameBytes(
        com.google.protobuf.ByteString value) {
      if (value == null) { throw new NullPointerException(); }
      checkByteStringIsUtf8(value);
      jobName_ = value;
      bitField0_ |= 0x00000001;
      onChanged();
      return this;
    }

    private java.lang.Object sinkTopic_ = "";
    /**
     * <pre>
     * Sink topic where full-state events are written
     * </pre>
     *
     * <code>string sink_topic = 2 [json_name = "sinkTopic"];</code>
     * @return The sinkTopic.
     */
    public java.lang.String getSinkTopic() {
      java.lang.Object ref = sinkTopic_;
      if (!(ref instanceof java.lang.String)) {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        sinkTopic_ = s;
        return s;
      } else {
        return (java.lang.String) ref;
      }
    }
    /**
     * <pre>
     * Sink topic where full-state events are written
     * </pre>
     *
     * <code>string sink_topic = 2 [json_name = "sinkTopic"];</code>
     * @return The bytes for sinkTopic.
     */
    public com.google.protobuf.ByteString
        getSinkTopicBytes() {
      java.lang.Object ref = sinkTopic_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        sinkTopic_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    /**
     * <pre>
     * Sink topic where full-state events are written
     * </pre>
     *
     * <code>string sink_topic = 2 [json_name = "sinkTopic"];</code>
     * @param value The sinkTopic to set.
     * @return This builder for chaining.
     */
    public Builder setSinkTopic(
        java.lang.String value) {
      if (value == null) { throw new NullPointerException(); }
      sinkTopic_ = value;
      bitField0_ |= 0x00000002;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Sink topic where full-state events are written
     * </pre>
     *
     * <code>string sink_topic = 2 [json_name = "sinkTopic"];</code>
     * @return This builder for chaining.
     */
    public Builder clearSinkTopic() {
      sinkTopic_ = getDefaultInstance().getSinkTopic();
      bitField0_ = (bitField0_ & ~0x00000002);
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Sink topic where full-state events are written
     * </pre>
     *
     * <code>string sink_topic = 2 [json_name = "sinkTopic"];</code>
     * @param value The bytes for sinkTopic to set.
     * @return This builder for chaining.
     */
    public Builder setSinkTopicBytes(
        com.google.protobuf.ByteString value) {
      if (value == null) { throw new NullPointerException(); }
      checkByteStringIsUtf8(value);
      sinkTopic_ = value;
      bitField0_ |= 0x00000002;
      onChanged();
      return this;
    }

    private java.lang.Object flinkSql_ = "";
    /**
     * <pre>
     * Generated Flink SQL for batch reconciliation
     * This wraps the user's original SQL query
     * </pre>
     *
     * <code>string flink_sql = 3 [json_name = "flinkSql"];</code>
     * @return The flinkSql.
     */
    public java.lang.String getFlinkSql() {
      java.lang.Object ref = flinkSql_;
      if (!(ref instanceof java.lang.String)) {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        flinkSql_ = s;
        return s;
      } else {
        return (java.lang.String) ref;
      }
    }
    /**
     * <pre>
     * Generated Flink SQL for batch reconciliation
     * This wraps the user's original SQL query
     * </pre>
     *
     * <code>string flink_sql = 3 [json_name = "flinkSql"];</code>
     * @return The bytes for flinkSql.
     */
    public com.google.protobuf.ByteString
        getFlinkSqlBytes() {
      java.lang.Object ref = flinkSql_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        flinkSql_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    /**
     * <pre>
     * Generated Flink SQL for batch reconciliation
     * This wraps the user's original SQL query
     * </pre>
     *
     * <code>string flink_sql = 3 [json_name = "flinkSql"];</code>
     * @param value The flinkSql to set.
     * @return This builder for chaining.
     */
    public Builder setFlinkSql(
        java.lang.String value) {
      if (value == null) { throw new NullPointerException(); }
      flinkSql_ = value;
      bitField0_ |= 0x00000004;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Generated Flink SQL for batch reconciliation
     * This wraps the user's original SQL query
     * </pre>
     *
     * <code>string flink_sql = 3 [json_name = "flinkSql"];</code>
     * @return This builder for chaining.
     */
    public Builder clearFlinkSql() {
      flinkSql_ = getDefaultInstance().getFlinkSql();
      bitField0_ = (bitField0_ & ~0x00000004);
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Generated Flink SQL for batch reconciliation
     * This wraps the user's original SQL query
     * </pre>
     *
     * <code>string flink_sql = 3 [json_name = "flinkSql"];</code>
     * @param value The bytes for flinkSql to set.
     * @return This builder for chaining.
     */
    public Builder setFlinkSqlBytes(
        com.google.protobuf.ByteString value) {
      if (value == null) { throw new NullPointerException(); }
      checkByteStringIsUtf8(value);
      flinkSql_ = value;
      bitField0_ |= 0x00000004;
      onChanged();
      return this;
    }

    private com.google.protobuf.LazyStringArrayList sourceTables_ =
        com.google.protobuf.LazyStringArrayList.emptyList();
    private void ensureSourceTablesIsMutable() {
      if (!sourceTables_.isModifiable()) {
        sourceTables_ = new com.google.protobuf.LazyStringArrayList(sourceTables_);
      }
      bitField0_ |= 0x00000008;
    }
    /**
     * <pre>
     * Source Iceberg tables referenced in the job
     * </pre>
     *
     * <code>repeated string source_tables = 4 [json_name = "sourceTables"];</code>
     * @return A list containing the sourceTables.
     */
    public com.google.protobuf.ProtocolStringList
        getSourceTablesList() {
      sourceTables_.makeImmutable();
      return sourceTables_;
    }
    /**
     * <pre>
     * Source Iceberg tables referenced in the job
     * </pre>
     *
     * <code>repeated string source_tables = 4 [json_name = "sourceTables"];</code>
     * @return The count of sourceTables.
     */
    public int getSourceTablesCount() {
      return sourceTables_.size();
    }
    /**
     * <pre>
     * Source Iceberg tables referenced in the job
     * </pre>
     *
     * <code>repeated string source_tables = 4 [json_name = "sourceTables"];</code>
     * @param index The index of the element to return.
     * @return The sourceTables at the given index.
     */
    public java.lang.String getSourceTables(int index) {
      return sourceTables_.get(index);
    }
    /**
     * <pre>
     * Source Iceberg tables referenced in the job
     * </pre>
     *
     * <code>repeated string source_tables = 4 [json_name = "sourceTables"];</code>
     * @param index The index of the value to return.
     * @return The bytes of the sourceTables at the given index.
     */
    public com.google.protobuf.ByteString
        getSourceTablesBytes(int index) {
      return sourceTables_.getByteString(index);
    }
    /**
     * <pre>
     * Source Iceberg tables referenced in the job
     * </pre>
     *
     * <code>repeated string source_tables = 4 [json_name = "sourceTables"];</code>
     * @param index The index to set the value at.
     * @param value The sourceTables to set.
     * @return This builder for chaining.
     */
    public Builder setSourceTables(
        int index, java.lang.String value) {
      if (value == null) { throw new NullPointerException(); }
      ensureSourceTablesIsMutable();
      sourceTables_.set(index, value);
      bitField0_ |= 0x00000008;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Source Iceberg tables referenced in the job
     * </pre>
     *
     * <code>repeated string source_tables = 4 [json_name = "sourceTables"];</code>
     * @param value The sourceTables to add.
     * @return This builder for chaining.
     */
    public Builder addSourceTables(
        java.lang.String value) {
      if (value == null) { throw new NullPointerException(); }
      ensureSourceTablesIsMutable();
      sourceTables_.add(value);
      bitField0_ |= 0x00000008;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Source Iceberg tables referenced in the job
     * </pre>
     *
     * <code>repeated string source_tables = 4 [json_name = "sourceTables"];</code>
     * @param values The sourceTables to add.
     * @return This builder for chaining.
     */
    public Builder addAllSourceTables(
        java.lang.Iterable<java.lang.String> values) {
      ensureSourceTablesIsMutable();
      com.google.protobuf.AbstractMessageLite.Builder.addAll(
          values, sourceTables_);
      bitField0_ |= 0x00000008;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Source Iceberg tables referenced in the job
     * </pre>
     *
     * <code>repeated string source_tables = 4 [json_name = "sourceTables"];</code>
     * @return This builder for chaining.
     */
    public Builder clearSourceTables() {
      sourceTables_ =
        com.google.protobuf.LazyStringArrayList.emptyList();
      bitField0_ = (bitField0_ & ~0x00000008);;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Source Iceberg tables referenced in the job
     * </pre>
     *
     * <code>repeated string source_tables = 4 [json_name = "sourceTables"];</code>
     * @param value The bytes of the sourceTables to add.
     * @return This builder for chaining.
     */
    public Builder addSourceTablesBytes(
        com.google.protobuf.ByteString value) {
      if (value == null) { throw new NullPointerException(); }
      checkByteStringIsUtf8(value);
      ensureSourceTablesIsMutable();
      sourceTables_.add(value);
      bitField0_ |= 0x00000008;
      onChanged();
      return this;
    }

    private java.lang.Object primaryKey_ = "";
    /**
     * <pre>
     * Primary key for output records
     * </pre>
     *
     * <code>string primary_key = 5 [json_name = "primaryKey"];</code>
     * @return The primaryKey.
     */
    public java.lang.String getPrimaryKey() {
      java.lang.Object ref = primaryKey_;
      if (!(ref instanceof java.lang.String)) {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        primaryKey_ = s;
        return s;
      } else {
        return (java.lang.String) ref;
      }
    }
    /**
     * <pre>
     * Primary key for output records
     * </pre>
     *
     * <code>string primary_key = 5 [json_name = "primaryKey"];</code>
     * @return The bytes for primaryKey.
     */
    public com.google.protobuf.ByteString
        getPrimaryKeyBytes() {
      java.lang.Object ref = primaryKey_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        primaryKey_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    /**
     * <pre>
     * Primary key for output records
     * </pre>
     *
     * <code>string primary_key = 5 [json_name = "primaryKey"];</code>
     * @param value The primaryKey to set.
     * @return This builder for chaining.
     */
    public Builder setPrimaryKey(
        java.lang.String value) {
      if (value == null) { throw new NullPointerException(); }
      primaryKey_ = value;
      bitField0_ |= 0x00000010;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Primary key for output records
     * </pre>
     *
     * <code>string primary_key = 5 [json_name = "primaryKey"];</code>
     * @return This builder for chaining.
     */
    public Builder clearPrimaryKey() {
      primaryKey_ = getDefaultInstance().getPrimaryKey();
      bitField0_ = (bitField0_ & ~0x00000010);
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Primary key for output records
     * </pre>
     *
     * <code>string primary_key = 5 [json_name = "primaryKey"];</code>
     * @param value The bytes for primaryKey to set.
     * @return This builder for chaining.
     */
    public Builder setPrimaryKeyBytes(
        com.google.protobuf.ByteString value) {
      if (value == null) { throw new NullPointerException(); }
      checkByteStringIsUtf8(value);
      primaryKey_ = value;
      bitField0_ |= 0x00000010;
      onChanged();
      return this;
    }

    private int parallelism_ ;
    /**
     * <pre>
     * Parallelism for the batch job
     * </pre>
     *
     * <code>int32 parallelism = 6 [json_name = "parallelism"];</code>
     * @return The parallelism.
     */
    @java.lang.Override
    public int getParallelism() {
      return parallelism_;
    }
    /**
     * <pre>
     * Parallelism for the batch job
     * </pre>
     *
     * <code>int32 parallelism = 6 [json_name = "parallelism"];</code>
     * @param value The parallelism to set.
     * @return This builder for chaining.
     */
    public Builder setParallelism(int value) {

      parallelism_ = value;
      bitField0_ |= 0x00000020;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Parallelism for the batch job
     * </pre>
     *
     * <code>int32 parallelism = 6 [json_name = "parallelism"];</code>
     * @return This builder for chaining.
     */
    public Builder clearParallelism() {
      bitField0_ = (bitField0_ & ~0x00000020);
      parallelism_ = 0;
      onChanged();
      return this;
    }

    private long expectedRuntimeMs_ ;
    /**
     * <pre>
     * Expected runtime (for monitoring)
     * </pre>
     *
     * <code>int64 expected_runtime_ms = 7 [json_name = "expectedRuntimeMs"];</code>
     * @return The expectedRuntimeMs.
     */
    @java.lang.Override
    public long getExpectedRuntimeMs() {
      return expectedRuntimeMs_;
    }
    /**
     * <pre>
     * Expected runtime (for monitoring)
     * </pre>
     *
     * <code>int64 expected_runtime_ms = 7 [json_name = "expectedRuntimeMs"];</code>
     * @param value The expectedRuntimeMs to set.
     * @return This builder for chaining.
     */
    public Builder setExpectedRuntimeMs(long value) {

      expectedRuntimeMs_ = value;
      bitField0_ |= 0x00000040;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Expected runtime (for monitoring)
     * </pre>
     *
     * <code>int64 expected_runtime_ms = 7 [json_name = "expectedRuntimeMs"];</code>
     * @return This builder for chaining.
     */
    public Builder clearExpectedRuntimeMs() {
      bitField0_ = (bitField0_ & ~0x00000040);
      expectedRuntimeMs_ = 0L;
      onChanged();
      return this;
    }
    @java.lang.Override
    public final Builder setUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return super.setUnknownFields(unknownFields);
    }

    @java.lang.Override
    public final Builder mergeUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return super.mergeUnknownFields(unknownFields);
    }


    // @@protoc_insertion_point(builder_scope:datapower.noesis.v1.BatchReconciliationJobSpec)
  }

  // @@protoc_insertion_point(class_scope:datapower.noesis.v1.BatchReconciliationJobSpec)
  private static final datapower.noesis.v1.BatchReconciliationJobSpec DEFAULT_INSTANCE;
  static {
    DEFAULT_INSTANCE = new datapower.noesis.v1.BatchReconciliationJobSpec();
  }

  public static datapower.noesis.v1.BatchReconciliationJobSpec getDefaultInstance() {
    return DEFAULT_INSTANCE;
  }

  private static final com.google.protobuf.Parser<BatchReconciliationJobSpec>
      PARSER = new com.google.protobuf.AbstractParser<BatchReconciliationJobSpec>() {
    @java.lang.Override
    public BatchReconciliationJobSpec parsePartialFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      Builder builder = newBuilder();
      try {
        builder.mergeFrom(input, extensionRegistry);
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(builder.buildPartial());
      } catch (com.google.protobuf.UninitializedMessageException e) {
        throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(e)
            .setUnfinishedMessage(builder.buildPartial());
      }
      return builder.buildPartial();
    }
  };

  public static com.google.protobuf.Parser<BatchReconciliationJobSpec> parser() {
    return PARSER;
  }

  @java.lang.Override
  public com.google.protobuf.Parser<BatchReconciliationJobSpec> getParserForType() {
    return PARSER;
  }

  @java.lang.Override
  public datapower.noesis.v1.BatchReconciliationJobSpec getDefaultInstanceForType() {
    return DEFAULT_INSTANCE;
  }

}

