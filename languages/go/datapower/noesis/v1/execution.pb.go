// Execution Plan Protocol
// ------------------------
// Defines the execution plan generated by the pipeline planner (runner.Plan()).
// The planner analyzes the pipeline definition, validates SQL against schemas,
// determines the execution strategy, and generates job specifications.
//
// Execution Strategies:
// - BATCH_ONLY: All fields are immutable, only batch reconciliation needed
// - STREAMING_ONLY: All fields are mutable, only streaming jobs needed
// - HYBRID: Mix of mutable (streaming) and immutable (batch) fields
//
// The ExecutionPlan is consumed by the RunPipeline workflow to orchestrate execution.

// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.10
// 	protoc        (unknown)
// source: datapower/noesis/v1/execution.proto

package noesisv1

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

type ExecutionStrategy int32

const (
	ExecutionStrategy_STRATEGY_UNSPECIFIED ExecutionStrategy = 0
	// All target fields are immutable, only batch processing needed
	// No streaming jobs are created
	ExecutionStrategy_BATCH_ONLY ExecutionStrategy = 1
	// All target fields are mutable and come from streaming sources
	// Only streaming jobs are created, no batch reconciliation
	ExecutionStrategy_STREAMING_ONLY ExecutionStrategy = 2
	// Mix of mutable (from streaming sources) and immutable (from batch sources)
	// Both streaming jobs AND batch reconciliation are created
	ExecutionStrategy_HYBRID ExecutionStrategy = 3
)

// Enum value maps for ExecutionStrategy.
var (
	ExecutionStrategy_name = map[int32]string{
		0: "STRATEGY_UNSPECIFIED",
		1: "BATCH_ONLY",
		2: "STREAMING_ONLY",
		3: "HYBRID",
	}
	ExecutionStrategy_value = map[string]int32{
		"STRATEGY_UNSPECIFIED": 0,
		"BATCH_ONLY":           1,
		"STREAMING_ONLY":       2,
		"HYBRID":               3,
	}
)

func (x ExecutionStrategy) Enum() *ExecutionStrategy {
	p := new(ExecutionStrategy)
	*p = x
	return p
}

func (x ExecutionStrategy) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (ExecutionStrategy) Descriptor() protoreflect.EnumDescriptor {
	return file_datapower_noesis_v1_execution_proto_enumTypes[0].Descriptor()
}

func (ExecutionStrategy) Type() protoreflect.EnumType {
	return &file_datapower_noesis_v1_execution_proto_enumTypes[0]
}

func (x ExecutionStrategy) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use ExecutionStrategy.Descriptor instead.
func (ExecutionStrategy) EnumDescriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_execution_proto_rawDescGZIP(), []int{0}
}

// ExecutionMode determines how the workflow executes
type ExecutionMode int32

const (
	ExecutionMode_EXECUTION_MODE_UNSPECIFIED ExecutionMode = 0
	// First-time deployment: deploy streaming jobs, then run batch
	ExecutionMode_INITIAL_DEPLOYMENT ExecutionMode = 1
	// Scheduled batch run: skip streaming job deployment
	ExecutionMode_SCHEDULED_RUN ExecutionMode = 2
	// Manual trigger: can be either mode depending on context
	ExecutionMode_MANUAL ExecutionMode = 3
)

// Enum value maps for ExecutionMode.
var (
	ExecutionMode_name = map[int32]string{
		0: "EXECUTION_MODE_UNSPECIFIED",
		1: "INITIAL_DEPLOYMENT",
		2: "SCHEDULED_RUN",
		3: "MANUAL",
	}
	ExecutionMode_value = map[string]int32{
		"EXECUTION_MODE_UNSPECIFIED": 0,
		"INITIAL_DEPLOYMENT":         1,
		"SCHEDULED_RUN":              2,
		"MANUAL":                     3,
	}
)

func (x ExecutionMode) Enum() *ExecutionMode {
	p := new(ExecutionMode)
	*p = x
	return p
}

func (x ExecutionMode) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (ExecutionMode) Descriptor() protoreflect.EnumDescriptor {
	return file_datapower_noesis_v1_execution_proto_enumTypes[1].Descriptor()
}

func (ExecutionMode) Type() protoreflect.EnumType {
	return &file_datapower_noesis_v1_execution_proto_enumTypes[1]
}

func (x ExecutionMode) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use ExecutionMode.Descriptor instead.
func (ExecutionMode) EnumDescriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_execution_proto_rawDescGZIP(), []int{1}
}

type ExecutionStatus int32

const (
	ExecutionStatus_EXECUTION_STATUS_UNSPECIFIED ExecutionStatus = 0
	ExecutionStatus_RUNNING                      ExecutionStatus = 1
	ExecutionStatus_COMPLETED                    ExecutionStatus = 2
	ExecutionStatus_FAILED                       ExecutionStatus = 3
	ExecutionStatus_CANCELLED                    ExecutionStatus = 4
)

// Enum value maps for ExecutionStatus.
var (
	ExecutionStatus_name = map[int32]string{
		0: "EXECUTION_STATUS_UNSPECIFIED",
		1: "RUNNING",
		2: "COMPLETED",
		3: "FAILED",
		4: "CANCELLED",
	}
	ExecutionStatus_value = map[string]int32{
		"EXECUTION_STATUS_UNSPECIFIED": 0,
		"RUNNING":                      1,
		"COMPLETED":                    2,
		"FAILED":                       3,
		"CANCELLED":                    4,
	}
)

func (x ExecutionStatus) Enum() *ExecutionStatus {
	p := new(ExecutionStatus)
	*p = x
	return p
}

func (x ExecutionStatus) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (ExecutionStatus) Descriptor() protoreflect.EnumDescriptor {
	return file_datapower_noesis_v1_execution_proto_enumTypes[2].Descriptor()
}

func (ExecutionStatus) Type() protoreflect.EnumType {
	return &file_datapower_noesis_v1_execution_proto_enumTypes[2]
}

func (x ExecutionStatus) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use ExecutionStatus.Descriptor instead.
func (ExecutionStatus) EnumDescriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_execution_proto_rawDescGZIP(), []int{2}
}

// ExecutionPlan is the output of the planning phase
// It contains all information needed to execute the pipeline
type ExecutionPlan struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Pipeline name
	PipelineName string `protobuf:"bytes,1,opt,name=pipeline_name,json=pipelineName,proto3" json:"pipeline_name,omitempty"`
	// Determined execution strategy
	Strategy ExecutionStrategy `protobuf:"varint,2,opt,name=strategy,proto3,enum=datapower.noesis.v1.ExecutionStrategy" json:"strategy,omitempty"`
	// Streaming job specifications (empty for BATCH_ONLY)
	StreamingJobs []*StreamingJobSpec `protobuf:"bytes,3,rep,name=streaming_jobs,json=streamingJobs,proto3" json:"streaming_jobs,omitempty"`
	// Batch source specifications
	BatchSources []*BatchSourceSpec `protobuf:"bytes,4,rep,name=batch_sources,json=batchSources,proto3" json:"batch_sources,omitempty"`
	// Batch reconciliation job specification (may be null for STREAMING_ONLY)
	BatchReconciliation *BatchReconciliationJobSpec `protobuf:"bytes,5,opt,name=batch_reconciliation,json=batchReconciliation,proto3" json:"batch_reconciliation,omitempty"`
	// Planning metadata
	Metadata *PlanningMetadata `protobuf:"bytes,6,opt,name=metadata,proto3" json:"metadata,omitempty"`
	// The original pipeline definition (for reference)
	PipelineDefinition *PipelineDefinition `protobuf:"bytes,7,opt,name=pipeline_definition,json=pipelineDefinition,proto3" json:"pipeline_definition,omitempty"`
	unknownFields      protoimpl.UnknownFields
	sizeCache          protoimpl.SizeCache
}

func (x *ExecutionPlan) Reset() {
	*x = ExecutionPlan{}
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ExecutionPlan) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ExecutionPlan) ProtoMessage() {}

func (x *ExecutionPlan) ProtoReflect() protoreflect.Message {
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ExecutionPlan.ProtoReflect.Descriptor instead.
func (*ExecutionPlan) Descriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_execution_proto_rawDescGZIP(), []int{0}
}

func (x *ExecutionPlan) GetPipelineName() string {
	if x != nil {
		return x.PipelineName
	}
	return ""
}

func (x *ExecutionPlan) GetStrategy() ExecutionStrategy {
	if x != nil {
		return x.Strategy
	}
	return ExecutionStrategy_STRATEGY_UNSPECIFIED
}

func (x *ExecutionPlan) GetStreamingJobs() []*StreamingJobSpec {
	if x != nil {
		return x.StreamingJobs
	}
	return nil
}

func (x *ExecutionPlan) GetBatchSources() []*BatchSourceSpec {
	if x != nil {
		return x.BatchSources
	}
	return nil
}

func (x *ExecutionPlan) GetBatchReconciliation() *BatchReconciliationJobSpec {
	if x != nil {
		return x.BatchReconciliation
	}
	return nil
}

func (x *ExecutionPlan) GetMetadata() *PlanningMetadata {
	if x != nil {
		return x.Metadata
	}
	return nil
}

func (x *ExecutionPlan) GetPipelineDefinition() *PipelineDefinition {
	if x != nil {
		return x.PipelineDefinition
	}
	return nil
}

// StreamingJobSpec defines a Flink streaming job for real-time updates
// One streaming job is created per streaming source that contributes to mutable fields
type StreamingJobSpec struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Unique job name (e.g., "customer-360-view_orders_patcher")
	JobName string `protobuf:"bytes,1,opt,name=job_name,json=jobName,proto3" json:"job_name,omitempty"`
	// Source alias from pipeline definition
	SourceAlias string `protobuf:"bytes,2,opt,name=source_alias,json=sourceAlias,proto3" json:"source_alias,omitempty"`
	// Kafka topic to consume from
	KafkaTopic string `protobuf:"bytes,3,opt,name=kafka_topic,json=kafkaTopic,proto3" json:"kafka_topic,omitempty"`
	// Target fields that this job updates (all must be mutable=true)
	MutableFields []string `protobuf:"bytes,4,rep,name=mutable_fields,json=mutableFields,proto3" json:"mutable_fields,omitempty"`
	// Sink topic where patch events are written
	SinkTopic string `protobuf:"bytes,5,opt,name=sink_topic,json=sinkTopic,proto3" json:"sink_topic,omitempty"`
	// Generated Flink SQL for this streaming job
	FlinkSql string `protobuf:"bytes,6,opt,name=flink_sql,json=flinkSql,proto3" json:"flink_sql,omitempty"`
	// Primary key field for grouping
	PrimaryKey string `protobuf:"bytes,7,opt,name=primary_key,json=primaryKey,proto3" json:"primary_key,omitempty"`
	// Kafka consumer group ID
	ConsumerGroup string `protobuf:"bytes,8,opt,name=consumer_group,json=consumerGroup,proto3" json:"consumer_group,omitempty"`
	// State backend configuration
	StateBackend *StateBackendConfig `protobuf:"bytes,9,opt,name=state_backend,json=stateBackend,proto3" json:"state_backend,omitempty"`
	// Checkpointing configuration
	Checkpoint *CheckpointConfig `protobuf:"bytes,10,opt,name=checkpoint,proto3" json:"checkpoint,omitempty"`
	// Parallelism for this job
	Parallelism   int32 `protobuf:"varint,11,opt,name=parallelism,proto3" json:"parallelism,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *StreamingJobSpec) Reset() {
	*x = StreamingJobSpec{}
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *StreamingJobSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StreamingJobSpec) ProtoMessage() {}

func (x *StreamingJobSpec) ProtoReflect() protoreflect.Message {
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StreamingJobSpec.ProtoReflect.Descriptor instead.
func (*StreamingJobSpec) Descriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_execution_proto_rawDescGZIP(), []int{1}
}

func (x *StreamingJobSpec) GetJobName() string {
	if x != nil {
		return x.JobName
	}
	return ""
}

func (x *StreamingJobSpec) GetSourceAlias() string {
	if x != nil {
		return x.SourceAlias
	}
	return ""
}

func (x *StreamingJobSpec) GetKafkaTopic() string {
	if x != nil {
		return x.KafkaTopic
	}
	return ""
}

func (x *StreamingJobSpec) GetMutableFields() []string {
	if x != nil {
		return x.MutableFields
	}
	return nil
}

func (x *StreamingJobSpec) GetSinkTopic() string {
	if x != nil {
		return x.SinkTopic
	}
	return ""
}

func (x *StreamingJobSpec) GetFlinkSql() string {
	if x != nil {
		return x.FlinkSql
	}
	return ""
}

func (x *StreamingJobSpec) GetPrimaryKey() string {
	if x != nil {
		return x.PrimaryKey
	}
	return ""
}

func (x *StreamingJobSpec) GetConsumerGroup() string {
	if x != nil {
		return x.ConsumerGroup
	}
	return ""
}

func (x *StreamingJobSpec) GetStateBackend() *StateBackendConfig {
	if x != nil {
		return x.StateBackend
	}
	return nil
}

func (x *StreamingJobSpec) GetCheckpoint() *CheckpointConfig {
	if x != nil {
		return x.Checkpoint
	}
	return nil
}

func (x *StreamingJobSpec) GetParallelism() int32 {
	if x != nil {
		return x.Parallelism
	}
	return 0
}

// StateBackendConfig defines state storage for streaming jobs
type StateBackendConfig struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// State backend type (rocksdb, memory, filesystem)
	Type string `protobuf:"bytes,1,opt,name=type,proto3" json:"type,omitempty"`
	// For RocksDB: incremental checkpoints
	IncrementalCheckpoints bool `protobuf:"varint,2,opt,name=incremental_checkpoints,json=incrementalCheckpoints,proto3" json:"incremental_checkpoints,omitempty"`
	// Storage path (for persistent backends)
	StoragePath   string `protobuf:"bytes,3,opt,name=storage_path,json=storagePath,proto3" json:"storage_path,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *StateBackendConfig) Reset() {
	*x = StateBackendConfig{}
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *StateBackendConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StateBackendConfig) ProtoMessage() {}

func (x *StateBackendConfig) ProtoReflect() protoreflect.Message {
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StateBackendConfig.ProtoReflect.Descriptor instead.
func (*StateBackendConfig) Descriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_execution_proto_rawDescGZIP(), []int{2}
}

func (x *StateBackendConfig) GetType() string {
	if x != nil {
		return x.Type
	}
	return ""
}

func (x *StateBackendConfig) GetIncrementalCheckpoints() bool {
	if x != nil {
		return x.IncrementalCheckpoints
	}
	return false
}

func (x *StateBackendConfig) GetStoragePath() string {
	if x != nil {
		return x.StoragePath
	}
	return ""
}

// CheckpointConfig defines checkpointing behavior
type CheckpointConfig struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Checkpoint interval in milliseconds
	IntervalMs int64 `protobuf:"varint,1,opt,name=interval_ms,json=intervalMs,proto3" json:"interval_ms,omitempty"`
	// Checkpoint mode (exactly_once, at_least_once)
	Mode string `protobuf:"bytes,2,opt,name=mode,proto3" json:"mode,omitempty"`
	// Checkpoint timeout in milliseconds
	TimeoutMs int64 `protobuf:"varint,3,opt,name=timeout_ms,json=timeoutMs,proto3" json:"timeout_ms,omitempty"`
	// Min pause between checkpoints in milliseconds
	MinPauseMs int64 `protobuf:"varint,4,opt,name=min_pause_ms,json=minPauseMs,proto3" json:"min_pause_ms,omitempty"`
	// Max concurrent checkpoints
	MaxConcurrent int32 `protobuf:"varint,5,opt,name=max_concurrent,json=maxConcurrent,proto3" json:"max_concurrent,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *CheckpointConfig) Reset() {
	*x = CheckpointConfig{}
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CheckpointConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CheckpointConfig) ProtoMessage() {}

func (x *CheckpointConfig) ProtoReflect() protoreflect.Message {
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CheckpointConfig.ProtoReflect.Descriptor instead.
func (*CheckpointConfig) Descriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_execution_proto_rawDescGZIP(), []int{3}
}

func (x *CheckpointConfig) GetIntervalMs() int64 {
	if x != nil {
		return x.IntervalMs
	}
	return 0
}

func (x *CheckpointConfig) GetMode() string {
	if x != nil {
		return x.Mode
	}
	return ""
}

func (x *CheckpointConfig) GetTimeoutMs() int64 {
	if x != nil {
		return x.TimeoutMs
	}
	return 0
}

func (x *CheckpointConfig) GetMinPauseMs() int64 {
	if x != nil {
		return x.MinPauseMs
	}
	return 0
}

func (x *CheckpointConfig) GetMaxConcurrent() int32 {
	if x != nil {
		return x.MaxConcurrent
	}
	return 0
}

// BatchSourceSpec defines how to extract and load a batch source
type BatchSourceSpec struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Source alias from pipeline definition
	SourceAlias string `protobuf:"bytes,1,opt,name=source_alias,json=sourceAlias,proto3" json:"source_alias,omitempty"`
	// Target Iceberg table name
	IcebergTable string `protobuf:"bytes,2,opt,name=iceberg_table,json=icebergTable,proto3" json:"iceberg_table,omitempty"`
	// Whether this source needs extraction (false if already in Iceberg)
	NeedsExtraction bool `protobuf:"varint,3,opt,name=needs_extraction,json=needsExtraction,proto3" json:"needs_extraction,omitempty"`
	// Connector configuration (if needs_extraction=true)
	Connector *ConnectorConfig `protobuf:"bytes,4,opt,name=connector,proto3" json:"connector,omitempty"`
	// Desired parallelism for extraction
	Parallelism int32 `protobuf:"varint,5,opt,name=parallelism,proto3" json:"parallelism,omitempty"`
	// Schema for the source
	Schema []*SchemaField `protobuf:"bytes,6,rep,name=schema,proto3" json:"schema,omitempty"`
	// Estimated row count (for planning)
	EstimatedRows int64 `protobuf:"varint,7,opt,name=estimated_rows,json=estimatedRows,proto3" json:"estimated_rows,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *BatchSourceSpec) Reset() {
	*x = BatchSourceSpec{}
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *BatchSourceSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*BatchSourceSpec) ProtoMessage() {}

func (x *BatchSourceSpec) ProtoReflect() protoreflect.Message {
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use BatchSourceSpec.ProtoReflect.Descriptor instead.
func (*BatchSourceSpec) Descriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_execution_proto_rawDescGZIP(), []int{4}
}

func (x *BatchSourceSpec) GetSourceAlias() string {
	if x != nil {
		return x.SourceAlias
	}
	return ""
}

func (x *BatchSourceSpec) GetIcebergTable() string {
	if x != nil {
		return x.IcebergTable
	}
	return ""
}

func (x *BatchSourceSpec) GetNeedsExtraction() bool {
	if x != nil {
		return x.NeedsExtraction
	}
	return false
}

func (x *BatchSourceSpec) GetConnector() *ConnectorConfig {
	if x != nil {
		return x.Connector
	}
	return nil
}

func (x *BatchSourceSpec) GetParallelism() int32 {
	if x != nil {
		return x.Parallelism
	}
	return 0
}

func (x *BatchSourceSpec) GetSchema() []*SchemaField {
	if x != nil {
		return x.Schema
	}
	return nil
}

func (x *BatchSourceSpec) GetEstimatedRows() int64 {
	if x != nil {
		return x.EstimatedRows
	}
	return 0
}

// ConnectorConfig holds connector-specific configuration
type ConnectorConfig struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Connector type (e.g., "postgres", "mysql", "oracle")
	ConnectorType string `protobuf:"bytes,1,opt,name=connector_type,json=connectorType,proto3" json:"connector_type,omitempty"`
	// Docker image for the connector
	ConnectorImage string `protobuf:"bytes,2,opt,name=connector_image,json=connectorImage,proto3" json:"connector_image,omitempty"`
	// Connector version
	ConnectorVersion string `protobuf:"bytes,3,opt,name=connector_version,json=connectorVersion,proto3" json:"connector_version,omitempty"`
	// Connection configuration (credentials, endpoints, etc.)
	Config map[string]string `protobuf:"bytes,4,rep,name=config,proto3" json:"config,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	// Entity name in source system
	EntityName    string `protobuf:"bytes,5,opt,name=entity_name,json=entityName,proto3" json:"entity_name,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ConnectorConfig) Reset() {
	*x = ConnectorConfig{}
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ConnectorConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ConnectorConfig) ProtoMessage() {}

func (x *ConnectorConfig) ProtoReflect() protoreflect.Message {
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ConnectorConfig.ProtoReflect.Descriptor instead.
func (*ConnectorConfig) Descriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_execution_proto_rawDescGZIP(), []int{5}
}

func (x *ConnectorConfig) GetConnectorType() string {
	if x != nil {
		return x.ConnectorType
	}
	return ""
}

func (x *ConnectorConfig) GetConnectorImage() string {
	if x != nil {
		return x.ConnectorImage
	}
	return ""
}

func (x *ConnectorConfig) GetConnectorVersion() string {
	if x != nil {
		return x.ConnectorVersion
	}
	return ""
}

func (x *ConnectorConfig) GetConfig() map[string]string {
	if x != nil {
		return x.Config
	}
	return nil
}

func (x *ConnectorConfig) GetEntityName() string {
	if x != nil {
		return x.EntityName
	}
	return ""
}

// BatchReconciliationJobSpec defines the main batch transformation job
type BatchReconciliationJobSpec struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Unique job name (e.g., "customer-360-view_batch_reconciliation")
	JobName string `protobuf:"bytes,1,opt,name=job_name,json=jobName,proto3" json:"job_name,omitempty"`
	// Sink topic where full-state events are written
	SinkTopic string `protobuf:"bytes,2,opt,name=sink_topic,json=sinkTopic,proto3" json:"sink_topic,omitempty"`
	// Generated Flink SQL for batch reconciliation
	// This wraps the user's original SQL query
	FlinkSql string `protobuf:"bytes,3,opt,name=flink_sql,json=flinkSql,proto3" json:"flink_sql,omitempty"`
	// Source Iceberg tables referenced in the job
	SourceTables []string `protobuf:"bytes,4,rep,name=source_tables,json=sourceTables,proto3" json:"source_tables,omitempty"`
	// Primary key for output records
	PrimaryKey string `protobuf:"bytes,5,opt,name=primary_key,json=primaryKey,proto3" json:"primary_key,omitempty"`
	// Parallelism for the batch job
	Parallelism int32 `protobuf:"varint,6,opt,name=parallelism,proto3" json:"parallelism,omitempty"`
	// Expected runtime (for monitoring)
	ExpectedRuntimeMs int64 `protobuf:"varint,7,opt,name=expected_runtime_ms,json=expectedRuntimeMs,proto3" json:"expected_runtime_ms,omitempty"`
	unknownFields     protoimpl.UnknownFields
	sizeCache         protoimpl.SizeCache
}

func (x *BatchReconciliationJobSpec) Reset() {
	*x = BatchReconciliationJobSpec{}
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *BatchReconciliationJobSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*BatchReconciliationJobSpec) ProtoMessage() {}

func (x *BatchReconciliationJobSpec) ProtoReflect() protoreflect.Message {
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use BatchReconciliationJobSpec.ProtoReflect.Descriptor instead.
func (*BatchReconciliationJobSpec) Descriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_execution_proto_rawDescGZIP(), []int{6}
}

func (x *BatchReconciliationJobSpec) GetJobName() string {
	if x != nil {
		return x.JobName
	}
	return ""
}

func (x *BatchReconciliationJobSpec) GetSinkTopic() string {
	if x != nil {
		return x.SinkTopic
	}
	return ""
}

func (x *BatchReconciliationJobSpec) GetFlinkSql() string {
	if x != nil {
		return x.FlinkSql
	}
	return ""
}

func (x *BatchReconciliationJobSpec) GetSourceTables() []string {
	if x != nil {
		return x.SourceTables
	}
	return nil
}

func (x *BatchReconciliationJobSpec) GetPrimaryKey() string {
	if x != nil {
		return x.PrimaryKey
	}
	return ""
}

func (x *BatchReconciliationJobSpec) GetParallelism() int32 {
	if x != nil {
		return x.Parallelism
	}
	return 0
}

func (x *BatchReconciliationJobSpec) GetExpectedRuntimeMs() int64 {
	if x != nil {
		return x.ExpectedRuntimeMs
	}
	return 0
}

// ExtractionSplit represents a partition of data to be extracted
// Returned by the PlanBatchSourceExtractionActivity
type ExtractionSplit struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Unique split identifier (e.g., "split-0", "split-1")
	SplitId string `protobuf:"bytes,1,opt,name=split_id,json=splitId,proto3" json:"split_id,omitempty"`
	// Source alias this split belongs to
	SourceAlias string `protobuf:"bytes,2,opt,name=source_alias,json=sourceAlias,proto3" json:"source_alias,omitempty"`
	// Filter condition for this split (e.g., "WHERE id BETWEEN 1 AND 1000000")
	FilterCondition string `protobuf:"bytes,3,opt,name=filter_condition,json=filterCondition,proto3" json:"filter_condition,omitempty"`
	// Estimated rows in this split
	EstimatedRows int64 `protobuf:"varint,4,opt,name=estimated_rows,json=estimatedRows,proto3" json:"estimated_rows,omitempty"`
	// Connector configuration
	Connector *ConnectorConfig `protobuf:"bytes,5,opt,name=connector,proto3" json:"connector,omitempty"`
	// Output configuration
	Output        *OutputConfig `protobuf:"bytes,6,opt,name=output,proto3" json:"output,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ExtractionSplit) Reset() {
	*x = ExtractionSplit{}
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ExtractionSplit) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ExtractionSplit) ProtoMessage() {}

func (x *ExtractionSplit) ProtoReflect() protoreflect.Message {
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ExtractionSplit.ProtoReflect.Descriptor instead.
func (*ExtractionSplit) Descriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_execution_proto_rawDescGZIP(), []int{7}
}

func (x *ExtractionSplit) GetSplitId() string {
	if x != nil {
		return x.SplitId
	}
	return ""
}

func (x *ExtractionSplit) GetSourceAlias() string {
	if x != nil {
		return x.SourceAlias
	}
	return ""
}

func (x *ExtractionSplit) GetFilterCondition() string {
	if x != nil {
		return x.FilterCondition
	}
	return ""
}

func (x *ExtractionSplit) GetEstimatedRows() int64 {
	if x != nil {
		return x.EstimatedRows
	}
	return 0
}

func (x *ExtractionSplit) GetConnector() *ConnectorConfig {
	if x != nil {
		return x.Connector
	}
	return nil
}

func (x *ExtractionSplit) GetOutput() *OutputConfig {
	if x != nil {
		return x.Output
	}
	return nil
}

// OutputConfig defines where extracted data is written
type OutputConfig struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Object storage bucket (e.g., "gs://my-bucket", "s3://my-bucket")
	Bucket string `protobuf:"bytes,1,opt,name=bucket,proto3" json:"bucket,omitempty"`
	// Path within bucket (e.g., "staging/customers_batch/run-xyz/partition-1")
	Path string `protobuf:"bytes,2,opt,name=path,proto3" json:"path,omitempty"`
	// Parquet file format options
	Parquet       *ParquetOptions `protobuf:"bytes,3,opt,name=parquet,proto3" json:"parquet,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *OutputConfig) Reset() {
	*x = OutputConfig{}
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *OutputConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*OutputConfig) ProtoMessage() {}

func (x *OutputConfig) ProtoReflect() protoreflect.Message {
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use OutputConfig.ProtoReflect.Descriptor instead.
func (*OutputConfig) Descriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_execution_proto_rawDescGZIP(), []int{8}
}

func (x *OutputConfig) GetBucket() string {
	if x != nil {
		return x.Bucket
	}
	return ""
}

func (x *OutputConfig) GetPath() string {
	if x != nil {
		return x.Path
	}
	return ""
}

func (x *OutputConfig) GetParquet() *ParquetOptions {
	if x != nil {
		return x.Parquet
	}
	return nil
}

type ParquetOptions struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Compression codec (snappy, gzip, lzo, zstd)
	Compression string `protobuf:"bytes,1,opt,name=compression,proto3" json:"compression,omitempty"`
	// Row group size
	RowGroupSize int64 `protobuf:"varint,2,opt,name=row_group_size,json=rowGroupSize,proto3" json:"row_group_size,omitempty"`
	// Page size
	PageSize      int64 `protobuf:"varint,3,opt,name=page_size,json=pageSize,proto3" json:"page_size,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ParquetOptions) Reset() {
	*x = ParquetOptions{}
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[9]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ParquetOptions) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ParquetOptions) ProtoMessage() {}

func (x *ParquetOptions) ProtoReflect() protoreflect.Message {
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[9]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ParquetOptions.ProtoReflect.Descriptor instead.
func (*ParquetOptions) Descriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_execution_proto_rawDescGZIP(), []int{9}
}

func (x *ParquetOptions) GetCompression() string {
	if x != nil {
		return x.Compression
	}
	return ""
}

func (x *ParquetOptions) GetRowGroupSize() int64 {
	if x != nil {
		return x.RowGroupSize
	}
	return 0
}

func (x *ParquetOptions) GetPageSize() int64 {
	if x != nil {
		return x.PageSize
	}
	return 0
}

// PlanningMetadata holds information about the planning process
type PlanningMetadata struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// When planning occurred
	PlannedAtEpochMs int64 `protobuf:"varint,1,opt,name=planned_at_epoch_ms,json=plannedAtEpochMs,proto3" json:"planned_at_epoch_ms,omitempty"`
	// Who/what initiated planning
	PlannedBy string `protobuf:"bytes,2,opt,name=planned_by,json=plannedBy,proto3" json:"planned_by,omitempty"`
	// Planning duration in milliseconds
	PlanningDurationMs int64 `protobuf:"varint,3,opt,name=planning_duration_ms,json=planningDurationMs,proto3" json:"planning_duration_ms,omitempty"`
	// SQL analysis results
	SqlAnalysis *SQLAnalysisResult `protobuf:"bytes,4,opt,name=sql_analysis,json=sqlAnalysis,proto3" json:"sql_analysis,omitempty"`
	// Strategy selection reasoning
	StrategyReason string `protobuf:"bytes,5,opt,name=strategy_reason,json=strategyReason,proto3" json:"strategy_reason,omitempty"`
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *PlanningMetadata) Reset() {
	*x = PlanningMetadata{}
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[10]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *PlanningMetadata) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PlanningMetadata) ProtoMessage() {}

func (x *PlanningMetadata) ProtoReflect() protoreflect.Message {
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[10]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PlanningMetadata.ProtoReflect.Descriptor instead.
func (*PlanningMetadata) Descriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_execution_proto_rawDescGZIP(), []int{10}
}

func (x *PlanningMetadata) GetPlannedAtEpochMs() int64 {
	if x != nil {
		return x.PlannedAtEpochMs
	}
	return 0
}

func (x *PlanningMetadata) GetPlannedBy() string {
	if x != nil {
		return x.PlannedBy
	}
	return ""
}

func (x *PlanningMetadata) GetPlanningDurationMs() int64 {
	if x != nil {
		return x.PlanningDurationMs
	}
	return 0
}

func (x *PlanningMetadata) GetSqlAnalysis() *SQLAnalysisResult {
	if x != nil {
		return x.SqlAnalysis
	}
	return nil
}

func (x *PlanningMetadata) GetStrategyReason() string {
	if x != nil {
		return x.StrategyReason
	}
	return ""
}

// SQLAnalysisResult captures the results of SQL query analysis
type SQLAnalysisResult struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Whether SQL is valid
	Valid bool `protobuf:"varint,1,opt,name=valid,proto3" json:"valid,omitempty"`
	// Parse errors (if any)
	ParseErrors []string `protobuf:"bytes,2,rep,name=parse_errors,json=parseErrors,proto3" json:"parse_errors,omitempty"`
	// Referenced source aliases
	ReferencedSources []string `protobuf:"bytes,3,rep,name=referenced_sources,json=referencedSources,proto3" json:"referenced_sources,omitempty"`
	// Referenced columns per source
	SourceColumns map[string]*ColumnList `protobuf:"bytes,4,rep,name=source_columns,json=sourceColumns,proto3" json:"source_columns,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	// Output columns (SELECT list)
	OutputColumns []string `protobuf:"bytes,5,rep,name=output_columns,json=outputColumns,proto3" json:"output_columns,omitempty"`
	// Query type (SELECT, JOIN, AGGREGATION, WINDOW)
	QueryType string `protobuf:"bytes,6,opt,name=query_type,json=queryType,proto3" json:"query_type,omitempty"`
	// Has GROUP BY clause
	HasGrouping bool `protobuf:"varint,7,opt,name=has_grouping,json=hasGrouping,proto3" json:"has_grouping,omitempty"`
	// Has window functions
	HasWindowing bool `protobuf:"varint,8,opt,name=has_windowing,json=hasWindowing,proto3" json:"has_windowing,omitempty"`
	// Join types used (INNER, LEFT, RIGHT, FULL)
	JoinTypes     []string `protobuf:"bytes,9,rep,name=join_types,json=joinTypes,proto3" json:"join_types,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SQLAnalysisResult) Reset() {
	*x = SQLAnalysisResult{}
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[11]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SQLAnalysisResult) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SQLAnalysisResult) ProtoMessage() {}

func (x *SQLAnalysisResult) ProtoReflect() protoreflect.Message {
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[11]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SQLAnalysisResult.ProtoReflect.Descriptor instead.
func (*SQLAnalysisResult) Descriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_execution_proto_rawDescGZIP(), []int{11}
}

func (x *SQLAnalysisResult) GetValid() bool {
	if x != nil {
		return x.Valid
	}
	return false
}

func (x *SQLAnalysisResult) GetParseErrors() []string {
	if x != nil {
		return x.ParseErrors
	}
	return nil
}

func (x *SQLAnalysisResult) GetReferencedSources() []string {
	if x != nil {
		return x.ReferencedSources
	}
	return nil
}

func (x *SQLAnalysisResult) GetSourceColumns() map[string]*ColumnList {
	if x != nil {
		return x.SourceColumns
	}
	return nil
}

func (x *SQLAnalysisResult) GetOutputColumns() []string {
	if x != nil {
		return x.OutputColumns
	}
	return nil
}

func (x *SQLAnalysisResult) GetQueryType() string {
	if x != nil {
		return x.QueryType
	}
	return ""
}

func (x *SQLAnalysisResult) GetHasGrouping() bool {
	if x != nil {
		return x.HasGrouping
	}
	return false
}

func (x *SQLAnalysisResult) GetHasWindowing() bool {
	if x != nil {
		return x.HasWindowing
	}
	return false
}

func (x *SQLAnalysisResult) GetJoinTypes() []string {
	if x != nil {
		return x.JoinTypes
	}
	return nil
}

type ColumnList struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Columns       []string               `protobuf:"bytes,1,rep,name=columns,proto3" json:"columns,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ColumnList) Reset() {
	*x = ColumnList{}
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[12]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ColumnList) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ColumnList) ProtoMessage() {}

func (x *ColumnList) ProtoReflect() protoreflect.Message {
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[12]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ColumnList.ProtoReflect.Descriptor instead.
func (*ColumnList) Descriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_execution_proto_rawDescGZIP(), []int{12}
}

func (x *ColumnList) GetColumns() []string {
	if x != nil {
		return x.Columns
	}
	return nil
}

// ExecutionResult captures the outcome of pipeline execution
type ExecutionResult struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Pipeline name
	PipelineName string `protobuf:"bytes,1,opt,name=pipeline_name,json=pipelineName,proto3" json:"pipeline_name,omitempty"`
	// Execution ID (workflow run ID)
	ExecutionId string `protobuf:"bytes,2,opt,name=execution_id,json=executionId,proto3" json:"execution_id,omitempty"`
	// Execution mode
	Mode ExecutionMode `protobuf:"varint,3,opt,name=mode,proto3,enum=datapower.noesis.v1.ExecutionMode" json:"mode,omitempty"`
	// Overall status
	Status ExecutionStatus `protobuf:"varint,4,opt,name=status,proto3,enum=datapower.noesis.v1.ExecutionStatus" json:"status,omitempty"`
	// Start and end times
	StartedAtEpochMs   int64 `protobuf:"varint,5,opt,name=started_at_epoch_ms,json=startedAtEpochMs,proto3" json:"started_at_epoch_ms,omitempty"`
	CompletedAtEpochMs int64 `protobuf:"varint,6,opt,name=completed_at_epoch_ms,json=completedAtEpochMs,proto3" json:"completed_at_epoch_ms,omitempty"`
	// Duration in milliseconds
	DurationMs int64 `protobuf:"varint,7,opt,name=duration_ms,json=durationMs,proto3" json:"duration_ms,omitempty"`
	// Streaming job results
	StreamingJobResults []*StreamingJobResult `protobuf:"bytes,8,rep,name=streaming_job_results,json=streamingJobResults,proto3" json:"streaming_job_results,omitempty"`
	// Batch extraction results
	ExtractionResults []*ExtractionResult `protobuf:"bytes,9,rep,name=extraction_results,json=extractionResults,proto3" json:"extraction_results,omitempty"`
	// Batch reconciliation result
	BatchResult *BatchJobResult `protobuf:"bytes,10,opt,name=batch_result,json=batchResult,proto3" json:"batch_result,omitempty"`
	// Error information (if failed)
	ErrorMessage    string `protobuf:"bytes,11,opt,name=error_message,json=errorMessage,proto3" json:"error_message,omitempty"`
	ErrorStackTrace string `protobuf:"bytes,12,opt,name=error_stack_trace,json=errorStackTrace,proto3" json:"error_stack_trace,omitempty"`
	// Metrics
	Metrics       *ExecutionMetrics `protobuf:"bytes,13,opt,name=metrics,proto3" json:"metrics,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ExecutionResult) Reset() {
	*x = ExecutionResult{}
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[13]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ExecutionResult) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ExecutionResult) ProtoMessage() {}

func (x *ExecutionResult) ProtoReflect() protoreflect.Message {
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[13]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ExecutionResult.ProtoReflect.Descriptor instead.
func (*ExecutionResult) Descriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_execution_proto_rawDescGZIP(), []int{13}
}

func (x *ExecutionResult) GetPipelineName() string {
	if x != nil {
		return x.PipelineName
	}
	return ""
}

func (x *ExecutionResult) GetExecutionId() string {
	if x != nil {
		return x.ExecutionId
	}
	return ""
}

func (x *ExecutionResult) GetMode() ExecutionMode {
	if x != nil {
		return x.Mode
	}
	return ExecutionMode_EXECUTION_MODE_UNSPECIFIED
}

func (x *ExecutionResult) GetStatus() ExecutionStatus {
	if x != nil {
		return x.Status
	}
	return ExecutionStatus_EXECUTION_STATUS_UNSPECIFIED
}

func (x *ExecutionResult) GetStartedAtEpochMs() int64 {
	if x != nil {
		return x.StartedAtEpochMs
	}
	return 0
}

func (x *ExecutionResult) GetCompletedAtEpochMs() int64 {
	if x != nil {
		return x.CompletedAtEpochMs
	}
	return 0
}

func (x *ExecutionResult) GetDurationMs() int64 {
	if x != nil {
		return x.DurationMs
	}
	return 0
}

func (x *ExecutionResult) GetStreamingJobResults() []*StreamingJobResult {
	if x != nil {
		return x.StreamingJobResults
	}
	return nil
}

func (x *ExecutionResult) GetExtractionResults() []*ExtractionResult {
	if x != nil {
		return x.ExtractionResults
	}
	return nil
}

func (x *ExecutionResult) GetBatchResult() *BatchJobResult {
	if x != nil {
		return x.BatchResult
	}
	return nil
}

func (x *ExecutionResult) GetErrorMessage() string {
	if x != nil {
		return x.ErrorMessage
	}
	return ""
}

func (x *ExecutionResult) GetErrorStackTrace() string {
	if x != nil {
		return x.ErrorStackTrace
	}
	return ""
}

func (x *ExecutionResult) GetMetrics() *ExecutionMetrics {
	if x != nil {
		return x.Metrics
	}
	return nil
}

type StreamingJobResult struct {
	state                protoimpl.MessageState `protogen:"open.v1"`
	JobName              string                 `protobuf:"bytes,1,opt,name=job_name,json=jobName,proto3" json:"job_name,omitempty"`
	FlinkJobId           string                 `protobuf:"bytes,2,opt,name=flink_job_id,json=flinkJobId,proto3" json:"flink_job_id,omitempty"`
	DeployedSuccessfully bool                   `protobuf:"varint,3,opt,name=deployed_successfully,json=deployedSuccessfully,proto3" json:"deployed_successfully,omitempty"`
	ErrorMessage         string                 `protobuf:"bytes,4,opt,name=error_message,json=errorMessage,proto3" json:"error_message,omitempty"`
	DeploymentTimeMs     int64                  `protobuf:"varint,5,opt,name=deployment_time_ms,json=deploymentTimeMs,proto3" json:"deployment_time_ms,omitempty"`
	unknownFields        protoimpl.UnknownFields
	sizeCache            protoimpl.SizeCache
}

func (x *StreamingJobResult) Reset() {
	*x = StreamingJobResult{}
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[14]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *StreamingJobResult) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StreamingJobResult) ProtoMessage() {}

func (x *StreamingJobResult) ProtoReflect() protoreflect.Message {
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[14]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StreamingJobResult.ProtoReflect.Descriptor instead.
func (*StreamingJobResult) Descriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_execution_proto_rawDescGZIP(), []int{14}
}

func (x *StreamingJobResult) GetJobName() string {
	if x != nil {
		return x.JobName
	}
	return ""
}

func (x *StreamingJobResult) GetFlinkJobId() string {
	if x != nil {
		return x.FlinkJobId
	}
	return ""
}

func (x *StreamingJobResult) GetDeployedSuccessfully() bool {
	if x != nil {
		return x.DeployedSuccessfully
	}
	return false
}

func (x *StreamingJobResult) GetErrorMessage() string {
	if x != nil {
		return x.ErrorMessage
	}
	return ""
}

func (x *StreamingJobResult) GetDeploymentTimeMs() int64 {
	if x != nil {
		return x.DeploymentTimeMs
	}
	return 0
}

type ExtractionResult struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	SplitId       string                 `protobuf:"bytes,1,opt,name=split_id,json=splitId,proto3" json:"split_id,omitempty"`
	SourceAlias   string                 `protobuf:"bytes,2,opt,name=source_alias,json=sourceAlias,proto3" json:"source_alias,omitempty"`
	Success       bool                   `protobuf:"varint,3,opt,name=success,proto3" json:"success,omitempty"`
	RowsExtracted int64                  `protobuf:"varint,4,opt,name=rows_extracted,json=rowsExtracted,proto3" json:"rows_extracted,omitempty"`
	BytesWritten  int64                  `protobuf:"varint,5,opt,name=bytes_written,json=bytesWritten,proto3" json:"bytes_written,omitempty"`
	DurationMs    int64                  `protobuf:"varint,6,opt,name=duration_ms,json=durationMs,proto3" json:"duration_ms,omitempty"`
	ErrorMessage  string                 `protobuf:"bytes,7,opt,name=error_message,json=errorMessage,proto3" json:"error_message,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ExtractionResult) Reset() {
	*x = ExtractionResult{}
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[15]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ExtractionResult) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ExtractionResult) ProtoMessage() {}

func (x *ExtractionResult) ProtoReflect() protoreflect.Message {
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[15]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ExtractionResult.ProtoReflect.Descriptor instead.
func (*ExtractionResult) Descriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_execution_proto_rawDescGZIP(), []int{15}
}

func (x *ExtractionResult) GetSplitId() string {
	if x != nil {
		return x.SplitId
	}
	return ""
}

func (x *ExtractionResult) GetSourceAlias() string {
	if x != nil {
		return x.SourceAlias
	}
	return ""
}

func (x *ExtractionResult) GetSuccess() bool {
	if x != nil {
		return x.Success
	}
	return false
}

func (x *ExtractionResult) GetRowsExtracted() int64 {
	if x != nil {
		return x.RowsExtracted
	}
	return 0
}

func (x *ExtractionResult) GetBytesWritten() int64 {
	if x != nil {
		return x.BytesWritten
	}
	return 0
}

func (x *ExtractionResult) GetDurationMs() int64 {
	if x != nil {
		return x.DurationMs
	}
	return 0
}

func (x *ExtractionResult) GetErrorMessage() string {
	if x != nil {
		return x.ErrorMessage
	}
	return ""
}

type BatchJobResult struct {
	state            protoimpl.MessageState `protogen:"open.v1"`
	JobName          string                 `protobuf:"bytes,1,opt,name=job_name,json=jobName,proto3" json:"job_name,omitempty"`
	FlinkJobId       string                 `protobuf:"bytes,2,opt,name=flink_job_id,json=flinkJobId,proto3" json:"flink_job_id,omitempty"`
	Success          bool                   `protobuf:"varint,3,opt,name=success,proto3" json:"success,omitempty"`
	RecordsProcessed int64                  `protobuf:"varint,4,opt,name=records_processed,json=recordsProcessed,proto3" json:"records_processed,omitempty"`
	RecordsWritten   int64                  `protobuf:"varint,5,opt,name=records_written,json=recordsWritten,proto3" json:"records_written,omitempty"`
	DurationMs       int64                  `protobuf:"varint,6,opt,name=duration_ms,json=durationMs,proto3" json:"duration_ms,omitempty"`
	ErrorMessage     string                 `protobuf:"bytes,7,opt,name=error_message,json=errorMessage,proto3" json:"error_message,omitempty"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *BatchJobResult) Reset() {
	*x = BatchJobResult{}
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[16]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *BatchJobResult) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*BatchJobResult) ProtoMessage() {}

func (x *BatchJobResult) ProtoReflect() protoreflect.Message {
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[16]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use BatchJobResult.ProtoReflect.Descriptor instead.
func (*BatchJobResult) Descriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_execution_proto_rawDescGZIP(), []int{16}
}

func (x *BatchJobResult) GetJobName() string {
	if x != nil {
		return x.JobName
	}
	return ""
}

func (x *BatchJobResult) GetFlinkJobId() string {
	if x != nil {
		return x.FlinkJobId
	}
	return ""
}

func (x *BatchJobResult) GetSuccess() bool {
	if x != nil {
		return x.Success
	}
	return false
}

func (x *BatchJobResult) GetRecordsProcessed() int64 {
	if x != nil {
		return x.RecordsProcessed
	}
	return 0
}

func (x *BatchJobResult) GetRecordsWritten() int64 {
	if x != nil {
		return x.RecordsWritten
	}
	return 0
}

func (x *BatchJobResult) GetDurationMs() int64 {
	if x != nil {
		return x.DurationMs
	}
	return 0
}

func (x *BatchJobResult) GetErrorMessage() string {
	if x != nil {
		return x.ErrorMessage
	}
	return ""
}

type ExecutionMetrics struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Total records processed
	TotalRecords int64 `protobuf:"varint,1,opt,name=total_records,json=totalRecords,proto3" json:"total_records,omitempty"`
	// Total bytes processed
	TotalBytes int64 `protobuf:"varint,2,opt,name=total_bytes,json=totalBytes,proto3" json:"total_bytes,omitempty"`
	// Extraction metrics
	ExtractionDurationMs int64 `protobuf:"varint,3,opt,name=extraction_duration_ms,json=extractionDurationMs,proto3" json:"extraction_duration_ms,omitempty"`
	ExtractionRecords    int64 `protobuf:"varint,4,opt,name=extraction_records,json=extractionRecords,proto3" json:"extraction_records,omitempty"`
	// Iceberg load metrics
	IcebergLoadDurationMs int64 `protobuf:"varint,5,opt,name=iceberg_load_duration_ms,json=icebergLoadDurationMs,proto3" json:"iceberg_load_duration_ms,omitempty"`
	IcebergRecordsLoaded  int64 `protobuf:"varint,6,opt,name=iceberg_records_loaded,json=icebergRecordsLoaded,proto3" json:"iceberg_records_loaded,omitempty"`
	// Batch job metrics
	BatchJobDurationMs  int64 `protobuf:"varint,7,opt,name=batch_job_duration_ms,json=batchJobDurationMs,proto3" json:"batch_job_duration_ms,omitempty"`
	BatchRecordsWritten int64 `protobuf:"varint,8,opt,name=batch_records_written,json=batchRecordsWritten,proto3" json:"batch_records_written,omitempty"`
	// Parallelism achieved
	ExtractionParallelism int32 `protobuf:"varint,9,opt,name=extraction_parallelism,json=extractionParallelism,proto3" json:"extraction_parallelism,omitempty"`
	BatchParallelism      int32 `protobuf:"varint,10,opt,name=batch_parallelism,json=batchParallelism,proto3" json:"batch_parallelism,omitempty"`
	unknownFields         protoimpl.UnknownFields
	sizeCache             protoimpl.SizeCache
}

func (x *ExecutionMetrics) Reset() {
	*x = ExecutionMetrics{}
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[17]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ExecutionMetrics) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ExecutionMetrics) ProtoMessage() {}

func (x *ExecutionMetrics) ProtoReflect() protoreflect.Message {
	mi := &file_datapower_noesis_v1_execution_proto_msgTypes[17]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ExecutionMetrics.ProtoReflect.Descriptor instead.
func (*ExecutionMetrics) Descriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_execution_proto_rawDescGZIP(), []int{17}
}

func (x *ExecutionMetrics) GetTotalRecords() int64 {
	if x != nil {
		return x.TotalRecords
	}
	return 0
}

func (x *ExecutionMetrics) GetTotalBytes() int64 {
	if x != nil {
		return x.TotalBytes
	}
	return 0
}

func (x *ExecutionMetrics) GetExtractionDurationMs() int64 {
	if x != nil {
		return x.ExtractionDurationMs
	}
	return 0
}

func (x *ExecutionMetrics) GetExtractionRecords() int64 {
	if x != nil {
		return x.ExtractionRecords
	}
	return 0
}

func (x *ExecutionMetrics) GetIcebergLoadDurationMs() int64 {
	if x != nil {
		return x.IcebergLoadDurationMs
	}
	return 0
}

func (x *ExecutionMetrics) GetIcebergRecordsLoaded() int64 {
	if x != nil {
		return x.IcebergRecordsLoaded
	}
	return 0
}

func (x *ExecutionMetrics) GetBatchJobDurationMs() int64 {
	if x != nil {
		return x.BatchJobDurationMs
	}
	return 0
}

func (x *ExecutionMetrics) GetBatchRecordsWritten() int64 {
	if x != nil {
		return x.BatchRecordsWritten
	}
	return 0
}

func (x *ExecutionMetrics) GetExtractionParallelism() int32 {
	if x != nil {
		return x.ExtractionParallelism
	}
	return 0
}

func (x *ExecutionMetrics) GetBatchParallelism() int32 {
	if x != nil {
		return x.BatchParallelism
	}
	return 0
}

var File_datapower_noesis_v1_execution_proto protoreflect.FileDescriptor

const file_datapower_noesis_v1_execution_proto_rawDesc = "" +
	"\n" +
	"#datapower/noesis/v1/execution.proto\x12\x13datapower.noesis.v1\x1a\"datapower/noesis/v1/pipeline.proto\"\x92\x04\n" +
	"\rExecutionPlan\x12#\n" +
	"\rpipeline_name\x18\x01 \x01(\tR\fpipelineName\x12B\n" +
	"\bstrategy\x18\x02 \x01(\x0e2&.datapower.noesis.v1.ExecutionStrategyR\bstrategy\x12L\n" +
	"\x0estreaming_jobs\x18\x03 \x03(\v2%.datapower.noesis.v1.StreamingJobSpecR\rstreamingJobs\x12I\n" +
	"\rbatch_sources\x18\x04 \x03(\v2$.datapower.noesis.v1.BatchSourceSpecR\fbatchSources\x12b\n" +
	"\x14batch_reconciliation\x18\x05 \x01(\v2/.datapower.noesis.v1.BatchReconciliationJobSpecR\x13batchReconciliation\x12A\n" +
	"\bmetadata\x18\x06 \x01(\v2%.datapower.noesis.v1.PlanningMetadataR\bmetadata\x12X\n" +
	"\x13pipeline_definition\x18\a \x01(\v2'.datapower.noesis.v1.PipelineDefinitionR\x12pipelineDefinition\"\xd3\x03\n" +
	"\x10StreamingJobSpec\x12\x19\n" +
	"\bjob_name\x18\x01 \x01(\tR\ajobName\x12!\n" +
	"\fsource_alias\x18\x02 \x01(\tR\vsourceAlias\x12\x1f\n" +
	"\vkafka_topic\x18\x03 \x01(\tR\n" +
	"kafkaTopic\x12%\n" +
	"\x0emutable_fields\x18\x04 \x03(\tR\rmutableFields\x12\x1d\n" +
	"\n" +
	"sink_topic\x18\x05 \x01(\tR\tsinkTopic\x12\x1b\n" +
	"\tflink_sql\x18\x06 \x01(\tR\bflinkSql\x12\x1f\n" +
	"\vprimary_key\x18\a \x01(\tR\n" +
	"primaryKey\x12%\n" +
	"\x0econsumer_group\x18\b \x01(\tR\rconsumerGroup\x12L\n" +
	"\rstate_backend\x18\t \x01(\v2'.datapower.noesis.v1.StateBackendConfigR\fstateBackend\x12E\n" +
	"\n" +
	"checkpoint\x18\n" +
	" \x01(\v2%.datapower.noesis.v1.CheckpointConfigR\n" +
	"checkpoint\x12 \n" +
	"\vparallelism\x18\v \x01(\x05R\vparallelism\"\x84\x01\n" +
	"\x12StateBackendConfig\x12\x12\n" +
	"\x04type\x18\x01 \x01(\tR\x04type\x127\n" +
	"\x17incremental_checkpoints\x18\x02 \x01(\bR\x16incrementalCheckpoints\x12!\n" +
	"\fstorage_path\x18\x03 \x01(\tR\vstoragePath\"\xaf\x01\n" +
	"\x10CheckpointConfig\x12\x1f\n" +
	"\vinterval_ms\x18\x01 \x01(\x03R\n" +
	"intervalMs\x12\x12\n" +
	"\x04mode\x18\x02 \x01(\tR\x04mode\x12\x1d\n" +
	"\n" +
	"timeout_ms\x18\x03 \x01(\x03R\ttimeoutMs\x12 \n" +
	"\fmin_pause_ms\x18\x04 \x01(\x03R\n" +
	"minPauseMs\x12%\n" +
	"\x0emax_concurrent\x18\x05 \x01(\x05R\rmaxConcurrent\"\xcb\x02\n" +
	"\x0fBatchSourceSpec\x12!\n" +
	"\fsource_alias\x18\x01 \x01(\tR\vsourceAlias\x12#\n" +
	"\riceberg_table\x18\x02 \x01(\tR\ficebergTable\x12)\n" +
	"\x10needs_extraction\x18\x03 \x01(\bR\x0fneedsExtraction\x12B\n" +
	"\tconnector\x18\x04 \x01(\v2$.datapower.noesis.v1.ConnectorConfigR\tconnector\x12 \n" +
	"\vparallelism\x18\x05 \x01(\x05R\vparallelism\x128\n" +
	"\x06schema\x18\x06 \x03(\v2 .datapower.noesis.v1.SchemaFieldR\x06schema\x12%\n" +
	"\x0eestimated_rows\x18\a \x01(\x03R\restimatedRows\"\xb4\x02\n" +
	"\x0fConnectorConfig\x12%\n" +
	"\x0econnector_type\x18\x01 \x01(\tR\rconnectorType\x12'\n" +
	"\x0fconnector_image\x18\x02 \x01(\tR\x0econnectorImage\x12+\n" +
	"\x11connector_version\x18\x03 \x01(\tR\x10connectorVersion\x12H\n" +
	"\x06config\x18\x04 \x03(\v20.datapower.noesis.v1.ConnectorConfig.ConfigEntryR\x06config\x12\x1f\n" +
	"\ventity_name\x18\x05 \x01(\tR\n" +
	"entityName\x1a9\n" +
	"\vConfigEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"\x8b\x02\n" +
	"\x1aBatchReconciliationJobSpec\x12\x19\n" +
	"\bjob_name\x18\x01 \x01(\tR\ajobName\x12\x1d\n" +
	"\n" +
	"sink_topic\x18\x02 \x01(\tR\tsinkTopic\x12\x1b\n" +
	"\tflink_sql\x18\x03 \x01(\tR\bflinkSql\x12#\n" +
	"\rsource_tables\x18\x04 \x03(\tR\fsourceTables\x12\x1f\n" +
	"\vprimary_key\x18\x05 \x01(\tR\n" +
	"primaryKey\x12 \n" +
	"\vparallelism\x18\x06 \x01(\x05R\vparallelism\x12.\n" +
	"\x13expected_runtime_ms\x18\a \x01(\x03R\x11expectedRuntimeMs\"\xa0\x02\n" +
	"\x0fExtractionSplit\x12\x19\n" +
	"\bsplit_id\x18\x01 \x01(\tR\asplitId\x12!\n" +
	"\fsource_alias\x18\x02 \x01(\tR\vsourceAlias\x12)\n" +
	"\x10filter_condition\x18\x03 \x01(\tR\x0ffilterCondition\x12%\n" +
	"\x0eestimated_rows\x18\x04 \x01(\x03R\restimatedRows\x12B\n" +
	"\tconnector\x18\x05 \x01(\v2$.datapower.noesis.v1.ConnectorConfigR\tconnector\x129\n" +
	"\x06output\x18\x06 \x01(\v2!.datapower.noesis.v1.OutputConfigR\x06output\"y\n" +
	"\fOutputConfig\x12\x16\n" +
	"\x06bucket\x18\x01 \x01(\tR\x06bucket\x12\x12\n" +
	"\x04path\x18\x02 \x01(\tR\x04path\x12=\n" +
	"\aparquet\x18\x03 \x01(\v2#.datapower.noesis.v1.ParquetOptionsR\aparquet\"u\n" +
	"\x0eParquetOptions\x12 \n" +
	"\vcompression\x18\x01 \x01(\tR\vcompression\x12$\n" +
	"\x0erow_group_size\x18\x02 \x01(\x03R\frowGroupSize\x12\x1b\n" +
	"\tpage_size\x18\x03 \x01(\x03R\bpageSize\"\x86\x02\n" +
	"\x10PlanningMetadata\x12-\n" +
	"\x13planned_at_epoch_ms\x18\x01 \x01(\x03R\x10plannedAtEpochMs\x12\x1d\n" +
	"\n" +
	"planned_by\x18\x02 \x01(\tR\tplannedBy\x120\n" +
	"\x14planning_duration_ms\x18\x03 \x01(\x03R\x12planningDurationMs\x12I\n" +
	"\fsql_analysis\x18\x04 \x01(\v2&.datapower.noesis.v1.SQLAnalysisResultR\vsqlAnalysis\x12'\n" +
	"\x0fstrategy_reason\x18\x05 \x01(\tR\x0estrategyReason\"\xed\x03\n" +
	"\x11SQLAnalysisResult\x12\x14\n" +
	"\x05valid\x18\x01 \x01(\bR\x05valid\x12!\n" +
	"\fparse_errors\x18\x02 \x03(\tR\vparseErrors\x12-\n" +
	"\x12referenced_sources\x18\x03 \x03(\tR\x11referencedSources\x12`\n" +
	"\x0esource_columns\x18\x04 \x03(\v29.datapower.noesis.v1.SQLAnalysisResult.SourceColumnsEntryR\rsourceColumns\x12%\n" +
	"\x0eoutput_columns\x18\x05 \x03(\tR\routputColumns\x12\x1d\n" +
	"\n" +
	"query_type\x18\x06 \x01(\tR\tqueryType\x12!\n" +
	"\fhas_grouping\x18\a \x01(\bR\vhasGrouping\x12#\n" +
	"\rhas_windowing\x18\b \x01(\bR\fhasWindowing\x12\x1d\n" +
	"\n" +
	"join_types\x18\t \x03(\tR\tjoinTypes\x1aa\n" +
	"\x12SourceColumnsEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x125\n" +
	"\x05value\x18\x02 \x01(\v2\x1f.datapower.noesis.v1.ColumnListR\x05value:\x028\x01\"&\n" +
	"\n" +
	"ColumnList\x12\x18\n" +
	"\acolumns\x18\x01 \x03(\tR\acolumns\"\xdf\x05\n" +
	"\x0fExecutionResult\x12#\n" +
	"\rpipeline_name\x18\x01 \x01(\tR\fpipelineName\x12!\n" +
	"\fexecution_id\x18\x02 \x01(\tR\vexecutionId\x126\n" +
	"\x04mode\x18\x03 \x01(\x0e2\".datapower.noesis.v1.ExecutionModeR\x04mode\x12<\n" +
	"\x06status\x18\x04 \x01(\x0e2$.datapower.noesis.v1.ExecutionStatusR\x06status\x12-\n" +
	"\x13started_at_epoch_ms\x18\x05 \x01(\x03R\x10startedAtEpochMs\x121\n" +
	"\x15completed_at_epoch_ms\x18\x06 \x01(\x03R\x12completedAtEpochMs\x12\x1f\n" +
	"\vduration_ms\x18\a \x01(\x03R\n" +
	"durationMs\x12[\n" +
	"\x15streaming_job_results\x18\b \x03(\v2'.datapower.noesis.v1.StreamingJobResultR\x13streamingJobResults\x12T\n" +
	"\x12extraction_results\x18\t \x03(\v2%.datapower.noesis.v1.ExtractionResultR\x11extractionResults\x12F\n" +
	"\fbatch_result\x18\n" +
	" \x01(\v2#.datapower.noesis.v1.BatchJobResultR\vbatchResult\x12#\n" +
	"\rerror_message\x18\v \x01(\tR\ferrorMessage\x12*\n" +
	"\x11error_stack_trace\x18\f \x01(\tR\x0ferrorStackTrace\x12?\n" +
	"\ametrics\x18\r \x01(\v2%.datapower.noesis.v1.ExecutionMetricsR\ametrics\"\xd9\x01\n" +
	"\x12StreamingJobResult\x12\x19\n" +
	"\bjob_name\x18\x01 \x01(\tR\ajobName\x12 \n" +
	"\fflink_job_id\x18\x02 \x01(\tR\n" +
	"flinkJobId\x123\n" +
	"\x15deployed_successfully\x18\x03 \x01(\bR\x14deployedSuccessfully\x12#\n" +
	"\rerror_message\x18\x04 \x01(\tR\ferrorMessage\x12,\n" +
	"\x12deployment_time_ms\x18\x05 \x01(\x03R\x10deploymentTimeMs\"\xfc\x01\n" +
	"\x10ExtractionResult\x12\x19\n" +
	"\bsplit_id\x18\x01 \x01(\tR\asplitId\x12!\n" +
	"\fsource_alias\x18\x02 \x01(\tR\vsourceAlias\x12\x18\n" +
	"\asuccess\x18\x03 \x01(\bR\asuccess\x12%\n" +
	"\x0erows_extracted\x18\x04 \x01(\x03R\rrowsExtracted\x12#\n" +
	"\rbytes_written\x18\x05 \x01(\x03R\fbytesWritten\x12\x1f\n" +
	"\vduration_ms\x18\x06 \x01(\x03R\n" +
	"durationMs\x12#\n" +
	"\rerror_message\x18\a \x01(\tR\ferrorMessage\"\x83\x02\n" +
	"\x0eBatchJobResult\x12\x19\n" +
	"\bjob_name\x18\x01 \x01(\tR\ajobName\x12 \n" +
	"\fflink_job_id\x18\x02 \x01(\tR\n" +
	"flinkJobId\x12\x18\n" +
	"\asuccess\x18\x03 \x01(\bR\asuccess\x12+\n" +
	"\x11records_processed\x18\x04 \x01(\x03R\x10recordsProcessed\x12'\n" +
	"\x0frecords_written\x18\x05 \x01(\x03R\x0erecordsWritten\x12\x1f\n" +
	"\vduration_ms\x18\x06 \x01(\x03R\n" +
	"durationMs\x12#\n" +
	"\rerror_message\x18\a \x01(\tR\ferrorMessage\"\xf7\x03\n" +
	"\x10ExecutionMetrics\x12#\n" +
	"\rtotal_records\x18\x01 \x01(\x03R\ftotalRecords\x12\x1f\n" +
	"\vtotal_bytes\x18\x02 \x01(\x03R\n" +
	"totalBytes\x124\n" +
	"\x16extraction_duration_ms\x18\x03 \x01(\x03R\x14extractionDurationMs\x12-\n" +
	"\x12extraction_records\x18\x04 \x01(\x03R\x11extractionRecords\x127\n" +
	"\x18iceberg_load_duration_ms\x18\x05 \x01(\x03R\x15icebergLoadDurationMs\x124\n" +
	"\x16iceberg_records_loaded\x18\x06 \x01(\x03R\x14icebergRecordsLoaded\x121\n" +
	"\x15batch_job_duration_ms\x18\a \x01(\x03R\x12batchJobDurationMs\x122\n" +
	"\x15batch_records_written\x18\b \x01(\x03R\x13batchRecordsWritten\x125\n" +
	"\x16extraction_parallelism\x18\t \x01(\x05R\x15extractionParallelism\x12+\n" +
	"\x11batch_parallelism\x18\n" +
	" \x01(\x05R\x10batchParallelism*]\n" +
	"\x11ExecutionStrategy\x12\x18\n" +
	"\x14STRATEGY_UNSPECIFIED\x10\x00\x12\x0e\n" +
	"\n" +
	"BATCH_ONLY\x10\x01\x12\x12\n" +
	"\x0eSTREAMING_ONLY\x10\x02\x12\n" +
	"\n" +
	"\x06HYBRID\x10\x03*f\n" +
	"\rExecutionMode\x12\x1e\n" +
	"\x1aEXECUTION_MODE_UNSPECIFIED\x10\x00\x12\x16\n" +
	"\x12INITIAL_DEPLOYMENT\x10\x01\x12\x11\n" +
	"\rSCHEDULED_RUN\x10\x02\x12\n" +
	"\n" +
	"\x06MANUAL\x10\x03*j\n" +
	"\x0fExecutionStatus\x12 \n" +
	"\x1cEXECUTION_STATUS_UNSPECIFIED\x10\x00\x12\v\n" +
	"\aRUNNING\x10\x01\x12\r\n" +
	"\tCOMPLETED\x10\x02\x12\n" +
	"\n" +
	"\x06FAILED\x10\x03\x12\r\n" +
	"\tCANCELLED\x10\x04Bk\n" +
	"\x13datapower.noesis.v1P\x01ZRgithub.com/data-power-io/noesis-protocol/languages/go/datapower/noesis/v1;noesisv1b\x06proto3"

var (
	file_datapower_noesis_v1_execution_proto_rawDescOnce sync.Once
	file_datapower_noesis_v1_execution_proto_rawDescData []byte
)

func file_datapower_noesis_v1_execution_proto_rawDescGZIP() []byte {
	file_datapower_noesis_v1_execution_proto_rawDescOnce.Do(func() {
		file_datapower_noesis_v1_execution_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_datapower_noesis_v1_execution_proto_rawDesc), len(file_datapower_noesis_v1_execution_proto_rawDesc)))
	})
	return file_datapower_noesis_v1_execution_proto_rawDescData
}

var file_datapower_noesis_v1_execution_proto_enumTypes = make([]protoimpl.EnumInfo, 3)
var file_datapower_noesis_v1_execution_proto_msgTypes = make([]protoimpl.MessageInfo, 20)
var file_datapower_noesis_v1_execution_proto_goTypes = []any{
	(ExecutionStrategy)(0),             // 0: datapower.noesis.v1.ExecutionStrategy
	(ExecutionMode)(0),                 // 1: datapower.noesis.v1.ExecutionMode
	(ExecutionStatus)(0),               // 2: datapower.noesis.v1.ExecutionStatus
	(*ExecutionPlan)(nil),              // 3: datapower.noesis.v1.ExecutionPlan
	(*StreamingJobSpec)(nil),           // 4: datapower.noesis.v1.StreamingJobSpec
	(*StateBackendConfig)(nil),         // 5: datapower.noesis.v1.StateBackendConfig
	(*CheckpointConfig)(nil),           // 6: datapower.noesis.v1.CheckpointConfig
	(*BatchSourceSpec)(nil),            // 7: datapower.noesis.v1.BatchSourceSpec
	(*ConnectorConfig)(nil),            // 8: datapower.noesis.v1.ConnectorConfig
	(*BatchReconciliationJobSpec)(nil), // 9: datapower.noesis.v1.BatchReconciliationJobSpec
	(*ExtractionSplit)(nil),            // 10: datapower.noesis.v1.ExtractionSplit
	(*OutputConfig)(nil),               // 11: datapower.noesis.v1.OutputConfig
	(*ParquetOptions)(nil),             // 12: datapower.noesis.v1.ParquetOptions
	(*PlanningMetadata)(nil),           // 13: datapower.noesis.v1.PlanningMetadata
	(*SQLAnalysisResult)(nil),          // 14: datapower.noesis.v1.SQLAnalysisResult
	(*ColumnList)(nil),                 // 15: datapower.noesis.v1.ColumnList
	(*ExecutionResult)(nil),            // 16: datapower.noesis.v1.ExecutionResult
	(*StreamingJobResult)(nil),         // 17: datapower.noesis.v1.StreamingJobResult
	(*ExtractionResult)(nil),           // 18: datapower.noesis.v1.ExtractionResult
	(*BatchJobResult)(nil),             // 19: datapower.noesis.v1.BatchJobResult
	(*ExecutionMetrics)(nil),           // 20: datapower.noesis.v1.ExecutionMetrics
	nil,                                // 21: datapower.noesis.v1.ConnectorConfig.ConfigEntry
	nil,                                // 22: datapower.noesis.v1.SQLAnalysisResult.SourceColumnsEntry
	(*PipelineDefinition)(nil),         // 23: datapower.noesis.v1.PipelineDefinition
	(*SchemaField)(nil),                // 24: datapower.noesis.v1.SchemaField
}
var file_datapower_noesis_v1_execution_proto_depIdxs = []int32{
	0,  // 0: datapower.noesis.v1.ExecutionPlan.strategy:type_name -> datapower.noesis.v1.ExecutionStrategy
	4,  // 1: datapower.noesis.v1.ExecutionPlan.streaming_jobs:type_name -> datapower.noesis.v1.StreamingJobSpec
	7,  // 2: datapower.noesis.v1.ExecutionPlan.batch_sources:type_name -> datapower.noesis.v1.BatchSourceSpec
	9,  // 3: datapower.noesis.v1.ExecutionPlan.batch_reconciliation:type_name -> datapower.noesis.v1.BatchReconciliationJobSpec
	13, // 4: datapower.noesis.v1.ExecutionPlan.metadata:type_name -> datapower.noesis.v1.PlanningMetadata
	23, // 5: datapower.noesis.v1.ExecutionPlan.pipeline_definition:type_name -> datapower.noesis.v1.PipelineDefinition
	5,  // 6: datapower.noesis.v1.StreamingJobSpec.state_backend:type_name -> datapower.noesis.v1.StateBackendConfig
	6,  // 7: datapower.noesis.v1.StreamingJobSpec.checkpoint:type_name -> datapower.noesis.v1.CheckpointConfig
	8,  // 8: datapower.noesis.v1.BatchSourceSpec.connector:type_name -> datapower.noesis.v1.ConnectorConfig
	24, // 9: datapower.noesis.v1.BatchSourceSpec.schema:type_name -> datapower.noesis.v1.SchemaField
	21, // 10: datapower.noesis.v1.ConnectorConfig.config:type_name -> datapower.noesis.v1.ConnectorConfig.ConfigEntry
	8,  // 11: datapower.noesis.v1.ExtractionSplit.connector:type_name -> datapower.noesis.v1.ConnectorConfig
	11, // 12: datapower.noesis.v1.ExtractionSplit.output:type_name -> datapower.noesis.v1.OutputConfig
	12, // 13: datapower.noesis.v1.OutputConfig.parquet:type_name -> datapower.noesis.v1.ParquetOptions
	14, // 14: datapower.noesis.v1.PlanningMetadata.sql_analysis:type_name -> datapower.noesis.v1.SQLAnalysisResult
	22, // 15: datapower.noesis.v1.SQLAnalysisResult.source_columns:type_name -> datapower.noesis.v1.SQLAnalysisResult.SourceColumnsEntry
	1,  // 16: datapower.noesis.v1.ExecutionResult.mode:type_name -> datapower.noesis.v1.ExecutionMode
	2,  // 17: datapower.noesis.v1.ExecutionResult.status:type_name -> datapower.noesis.v1.ExecutionStatus
	17, // 18: datapower.noesis.v1.ExecutionResult.streaming_job_results:type_name -> datapower.noesis.v1.StreamingJobResult
	18, // 19: datapower.noesis.v1.ExecutionResult.extraction_results:type_name -> datapower.noesis.v1.ExtractionResult
	19, // 20: datapower.noesis.v1.ExecutionResult.batch_result:type_name -> datapower.noesis.v1.BatchJobResult
	20, // 21: datapower.noesis.v1.ExecutionResult.metrics:type_name -> datapower.noesis.v1.ExecutionMetrics
	15, // 22: datapower.noesis.v1.SQLAnalysisResult.SourceColumnsEntry.value:type_name -> datapower.noesis.v1.ColumnList
	23, // [23:23] is the sub-list for method output_type
	23, // [23:23] is the sub-list for method input_type
	23, // [23:23] is the sub-list for extension type_name
	23, // [23:23] is the sub-list for extension extendee
	0,  // [0:23] is the sub-list for field type_name
}

func init() { file_datapower_noesis_v1_execution_proto_init() }
func file_datapower_noesis_v1_execution_proto_init() {
	if File_datapower_noesis_v1_execution_proto != nil {
		return
	}
	file_datapower_noesis_v1_pipeline_proto_init()
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_datapower_noesis_v1_execution_proto_rawDesc), len(file_datapower_noesis_v1_execution_proto_rawDesc)),
			NumEnums:      3,
			NumMessages:   20,
			NumExtensions: 0,
			NumServices:   0,
		},
		GoTypes:           file_datapower_noesis_v1_execution_proto_goTypes,
		DependencyIndexes: file_datapower_noesis_v1_execution_proto_depIdxs,
		EnumInfos:         file_datapower_noesis_v1_execution_proto_enumTypes,
		MessageInfos:      file_datapower_noesis_v1_execution_proto_msgTypes,
	}.Build()
	File_datapower_noesis_v1_execution_proto = out.File
	file_datapower_noesis_v1_execution_proto_goTypes = nil
	file_datapower_noesis_v1_execution_proto_depIdxs = nil
}
