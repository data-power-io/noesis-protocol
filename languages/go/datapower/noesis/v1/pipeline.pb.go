// Pipeline Definition Protocol
// ---------------------------
// Defines the declarative YAML structure for data pipelines in the Iceberg-Parquet-Flink architecture.
// This proto matches the YAML format that users write to define their pipelines.
//
// Key Concepts:
// - Sources: Data inputs (batch Iceberg tables or streaming Kafka topics)
// - Sinks: Output destinations (Kafka topics for transformed events)
// - Target Schema: The contract for the final transformed data
// - Query: The SQL transformation logic
//
// The pipeline definition is parsed, validated, and used to generate an ExecutionPlan.

// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.10
// 	protoc        (unknown)
// source: datapower/noesis/v1/pipeline.proto

package noesisv1

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

type SourceType int32

const (
	SourceType_SOURCE_TYPE_UNSPECIFIED SourceType = 0
	SourceType_ICEBERG_TABLE           SourceType = 1
	SourceType_KAFKA_TOPIC             SourceType = 2
)

// Enum value maps for SourceType.
var (
	SourceType_name = map[int32]string{
		0: "SOURCE_TYPE_UNSPECIFIED",
		1: "ICEBERG_TABLE",
		2: "KAFKA_TOPIC",
	}
	SourceType_value = map[string]int32{
		"SOURCE_TYPE_UNSPECIFIED": 0,
		"ICEBERG_TABLE":           1,
		"KAFKA_TOPIC":             2,
	}
)

func (x SourceType) Enum() *SourceType {
	p := new(SourceType)
	*p = x
	return p
}

func (x SourceType) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (SourceType) Descriptor() protoreflect.EnumDescriptor {
	return file_datapower_noesis_v1_pipeline_proto_enumTypes[0].Descriptor()
}

func (SourceType) Type() protoreflect.EnumType {
	return &file_datapower_noesis_v1_pipeline_proto_enumTypes[0]
}

func (x SourceType) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use SourceType.Descriptor instead.
func (SourceType) EnumDescriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_pipeline_proto_rawDescGZIP(), []int{0}
}

// PipelineDefinition represents the complete declarative pipeline specification
// This matches the YAML structure that users define
type PipelineDefinition struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Unique pipeline identifier (must be DNS-safe)
	PipelineName string `protobuf:"bytes,1,opt,name=pipeline_name,json=pipelineName,proto3" json:"pipeline_name,omitempty"`
	// Cron schedule expression for batch execution (e.g., "0 2 * * *" for daily at 2 AM)
	Schedule string `protobuf:"bytes,2,opt,name=schedule,proto3" json:"schedule,omitempty"`
	// All data sources for this pipeline
	Sources []*Source `protobuf:"bytes,3,rep,name=sources,proto3" json:"sources,omitempty"`
	// Output sinks (typically Kafka topics)
	Sinks []*Sink `protobuf:"bytes,4,rep,name=sinks,proto3" json:"sinks,omitempty"`
	// Schema definition for the final transformed data
	TargetSchema *TargetSchema `protobuf:"bytes,5,opt,name=target_schema,json=targetSchema,proto3" json:"target_schema,omitempty"`
	// The SQL query that transforms sources into the target schema
	Query *Query `protobuf:"bytes,6,opt,name=query,proto3" json:"query,omitempty"`
	// Optional: Pipeline metadata
	Metadata      map[string]string `protobuf:"bytes,7,rep,name=metadata,proto3" json:"metadata,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *PipelineDefinition) Reset() {
	*x = PipelineDefinition{}
	mi := &file_datapower_noesis_v1_pipeline_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *PipelineDefinition) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PipelineDefinition) ProtoMessage() {}

func (x *PipelineDefinition) ProtoReflect() protoreflect.Message {
	mi := &file_datapower_noesis_v1_pipeline_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PipelineDefinition.ProtoReflect.Descriptor instead.
func (*PipelineDefinition) Descriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_pipeline_proto_rawDescGZIP(), []int{0}
}

func (x *PipelineDefinition) GetPipelineName() string {
	if x != nil {
		return x.PipelineName
	}
	return ""
}

func (x *PipelineDefinition) GetSchedule() string {
	if x != nil {
		return x.Schedule
	}
	return ""
}

func (x *PipelineDefinition) GetSources() []*Source {
	if x != nil {
		return x.Sources
	}
	return nil
}

func (x *PipelineDefinition) GetSinks() []*Sink {
	if x != nil {
		return x.Sinks
	}
	return nil
}

func (x *PipelineDefinition) GetTargetSchema() *TargetSchema {
	if x != nil {
		return x.TargetSchema
	}
	return nil
}

func (x *PipelineDefinition) GetQuery() *Query {
	if x != nil {
		return x.Query
	}
	return nil
}

func (x *PipelineDefinition) GetMetadata() map[string]string {
	if x != nil {
		return x.Metadata
	}
	return nil
}

// Source represents an input data source
type Source struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Alias used to reference this source in SQL queries
	Alias string `protobuf:"bytes,1,opt,name=alias,proto3" json:"alias,omitempty"`
	// Type of source (iceberg_table or kafka_topic)
	Type SourceType `protobuf:"varint,2,opt,name=type,proto3,enum=datapower.noesis.v1.SourceType" json:"type,omitempty"`
	// Fully qualified name (e.g., "raw.customers_db" for Iceberg, "raw-orders-events" for Kafka)
	Name string `protobuf:"bytes,3,opt,name=name,proto3" json:"name,omitempty"`
	// For Iceberg tables that are fed by streaming sources
	// This indicates the table has real-time updates
	StreamingSource *StreamingSource `protobuf:"bytes,4,opt,name=streaming_source,json=streamingSource,proto3" json:"streaming_source,omitempty"`
	// Schema definition for this source
	Schema []*SchemaField `protobuf:"bytes,5,rep,name=schema,proto3" json:"schema,omitempty"`
	// Optional: Partitioning information for optimization
	PartitionKeys []string `protobuf:"bytes,6,rep,name=partition_keys,json=partitionKeys,proto3" json:"partition_keys,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Source) Reset() {
	*x = Source{}
	mi := &file_datapower_noesis_v1_pipeline_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Source) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Source) ProtoMessage() {}

func (x *Source) ProtoReflect() protoreflect.Message {
	mi := &file_datapower_noesis_v1_pipeline_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Source.ProtoReflect.Descriptor instead.
func (*Source) Descriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_pipeline_proto_rawDescGZIP(), []int{1}
}

func (x *Source) GetAlias() string {
	if x != nil {
		return x.Alias
	}
	return ""
}

func (x *Source) GetType() SourceType {
	if x != nil {
		return x.Type
	}
	return SourceType_SOURCE_TYPE_UNSPECIFIED
}

func (x *Source) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *Source) GetStreamingSource() *StreamingSource {
	if x != nil {
		return x.StreamingSource
	}
	return nil
}

func (x *Source) GetSchema() []*SchemaField {
	if x != nil {
		return x.Schema
	}
	return nil
}

func (x *Source) GetPartitionKeys() []string {
	if x != nil {
		return x.PartitionKeys
	}
	return nil
}

// StreamingSource indicates that an Iceberg table is continuously updated from a stream
type StreamingSource struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Type of streaming source (currently only "kafka_topic")
	Type string `protobuf:"bytes,1,opt,name=type,proto3" json:"type,omitempty"`
	// Topic name (e.g., "raw-orders-events")
	Name string `protobuf:"bytes,2,opt,name=name,proto3" json:"name,omitempty"`
	// Consumer group for reading (optional)
	ConsumerGroup string `protobuf:"bytes,3,opt,name=consumer_group,json=consumerGroup,proto3" json:"consumer_group,omitempty"`
	// Starting offset strategy (latest, earliest, specific timestamp)
	StartOffset   string `protobuf:"bytes,4,opt,name=start_offset,json=startOffset,proto3" json:"start_offset,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *StreamingSource) Reset() {
	*x = StreamingSource{}
	mi := &file_datapower_noesis_v1_pipeline_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *StreamingSource) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StreamingSource) ProtoMessage() {}

func (x *StreamingSource) ProtoReflect() protoreflect.Message {
	mi := &file_datapower_noesis_v1_pipeline_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StreamingSource.ProtoReflect.Descriptor instead.
func (*StreamingSource) Descriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_pipeline_proto_rawDescGZIP(), []int{2}
}

func (x *StreamingSource) GetType() string {
	if x != nil {
		return x.Type
	}
	return ""
}

func (x *StreamingSource) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *StreamingSource) GetConsumerGroup() string {
	if x != nil {
		return x.ConsumerGroup
	}
	return ""
}

func (x *StreamingSource) GetStartOffset() string {
	if x != nil {
		return x.StartOffset
	}
	return ""
}

// SchemaField defines a single field in a source or target schema
type SchemaField struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Field name
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// Data type (STRING, LONG, INTEGER, DOUBLE, DECIMAL, BOOLEAN, DATE, TIMESTAMP, ARRAY, STRUCT)
	Type string `protobuf:"bytes,2,opt,name=type,proto3" json:"type,omitempty"`
	// Whether this field can be null
	Nullable bool `protobuf:"varint,3,opt,name=nullable,proto3" json:"nullable,omitempty"`
	// Optional: Default value
	DefaultValue string `protobuf:"bytes,4,opt,name=default_value,json=defaultValue,proto3" json:"default_value,omitempty"`
	// Optional: Field documentation
	Description string `protobuf:"bytes,5,opt,name=description,proto3" json:"description,omitempty"`
	// For DECIMAL types: precision and scale
	Precision int32 `protobuf:"varint,6,opt,name=precision,proto3" json:"precision,omitempty"`
	Scale     int32 `protobuf:"varint,7,opt,name=scale,proto3" json:"scale,omitempty"`
	// For ARRAY types: element type
	ElementType string `protobuf:"bytes,8,opt,name=element_type,json=elementType,proto3" json:"element_type,omitempty"`
	// For nested types: sub-fields
	Fields        []*SchemaField `protobuf:"bytes,9,rep,name=fields,proto3" json:"fields,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SchemaField) Reset() {
	*x = SchemaField{}
	mi := &file_datapower_noesis_v1_pipeline_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SchemaField) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SchemaField) ProtoMessage() {}

func (x *SchemaField) ProtoReflect() protoreflect.Message {
	mi := &file_datapower_noesis_v1_pipeline_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SchemaField.ProtoReflect.Descriptor instead.
func (*SchemaField) Descriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_pipeline_proto_rawDescGZIP(), []int{3}
}

func (x *SchemaField) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *SchemaField) GetType() string {
	if x != nil {
		return x.Type
	}
	return ""
}

func (x *SchemaField) GetNullable() bool {
	if x != nil {
		return x.Nullable
	}
	return false
}

func (x *SchemaField) GetDefaultValue() string {
	if x != nil {
		return x.DefaultValue
	}
	return ""
}

func (x *SchemaField) GetDescription() string {
	if x != nil {
		return x.Description
	}
	return ""
}

func (x *SchemaField) GetPrecision() int32 {
	if x != nil {
		return x.Precision
	}
	return 0
}

func (x *SchemaField) GetScale() int32 {
	if x != nil {
		return x.Scale
	}
	return 0
}

func (x *SchemaField) GetElementType() string {
	if x != nil {
		return x.ElementType
	}
	return ""
}

func (x *SchemaField) GetFields() []*SchemaField {
	if x != nil {
		return x.Fields
	}
	return nil
}

// Sink represents an output destination
type Sink struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Alias used to reference this sink in the query
	Alias string `protobuf:"bytes,1,opt,name=alias,proto3" json:"alias,omitempty"`
	// Type of sink (currently only "kafka_topic")
	Type string `protobuf:"bytes,2,opt,name=type,proto3" json:"type,omitempty"`
	// Topic name where transformed events will be written
	Name string `protobuf:"bytes,3,opt,name=name,proto3" json:"name,omitempty"`
	// Optional: Partitioning key for the sink topic
	PartitionKey string `protobuf:"bytes,4,opt,name=partition_key,json=partitionKey,proto3" json:"partition_key,omitempty"`
	// Optional: Serialization format (json, avro, protobuf)
	Format        string `protobuf:"bytes,5,opt,name=format,proto3" json:"format,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Sink) Reset() {
	*x = Sink{}
	mi := &file_datapower_noesis_v1_pipeline_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Sink) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Sink) ProtoMessage() {}

func (x *Sink) ProtoReflect() protoreflect.Message {
	mi := &file_datapower_noesis_v1_pipeline_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Sink.ProtoReflect.Descriptor instead.
func (*Sink) Descriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_pipeline_proto_rawDescGZIP(), []int{4}
}

func (x *Sink) GetAlias() string {
	if x != nil {
		return x.Alias
	}
	return ""
}

func (x *Sink) GetType() string {
	if x != nil {
		return x.Type
	}
	return ""
}

func (x *Sink) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *Sink) GetPartitionKey() string {
	if x != nil {
		return x.PartitionKey
	}
	return ""
}

func (x *Sink) GetFormat() string {
	if x != nil {
		return x.Format
	}
	return ""
}

// TargetSchema defines the contract for the transformed output data
type TargetSchema struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Name of the target entity (e.g., "Customer360")
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// Primary key field name
	PrimaryKey string `protobuf:"bytes,2,opt,name=primary_key,json=primaryKey,proto3" json:"primary_key,omitempty"`
	// All fields in the target schema
	Fields []*TargetField `protobuf:"bytes,3,rep,name=fields,proto3" json:"fields,omitempty"`
	// Optional: Composite primary key (if primary_key is not set)
	PrimaryKeyFields []string `protobuf:"bytes,4,rep,name=primary_key_fields,json=primaryKeyFields,proto3" json:"primary_key_fields,omitempty"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *TargetSchema) Reset() {
	*x = TargetSchema{}
	mi := &file_datapower_noesis_v1_pipeline_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TargetSchema) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TargetSchema) ProtoMessage() {}

func (x *TargetSchema) ProtoReflect() protoreflect.Message {
	mi := &file_datapower_noesis_v1_pipeline_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TargetSchema.ProtoReflect.Descriptor instead.
func (*TargetSchema) Descriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_pipeline_proto_rawDescGZIP(), []int{5}
}

func (x *TargetSchema) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *TargetSchema) GetPrimaryKey() string {
	if x != nil {
		return x.PrimaryKey
	}
	return ""
}

func (x *TargetSchema) GetFields() []*TargetField {
	if x != nil {
		return x.Fields
	}
	return nil
}

func (x *TargetSchema) GetPrimaryKeyFields() []string {
	if x != nil {
		return x.PrimaryKeyFields
	}
	return nil
}

// TargetField defines a field in the target schema with mutability semantics
type TargetField struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Field name
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// Data type
	Type string `protobuf:"bytes,2,opt,name=type,proto3" json:"type,omitempty"`
	// Mutability flag: determines processing strategy
	// - mutable: false -> computed in batch, immutable once created
	// - mutable: true -> can be updated by streaming jobs, subject to change
	Mutable bool `protobuf:"varint,3,opt,name=mutable,proto3" json:"mutable,omitempty"`
	// Whether this field can be null
	Nullable bool `protobuf:"varint,4,opt,name=nullable,proto3" json:"nullable,omitempty"`
	// Optional: Field description
	Description string `protobuf:"bytes,5,opt,name=description,proto3" json:"description,omitempty"`
	// For DECIMAL types
	Precision     int32 `protobuf:"varint,6,opt,name=precision,proto3" json:"precision,omitempty"`
	Scale         int32 `protobuf:"varint,7,opt,name=scale,proto3" json:"scale,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *TargetField) Reset() {
	*x = TargetField{}
	mi := &file_datapower_noesis_v1_pipeline_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TargetField) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TargetField) ProtoMessage() {}

func (x *TargetField) ProtoReflect() protoreflect.Message {
	mi := &file_datapower_noesis_v1_pipeline_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TargetField.ProtoReflect.Descriptor instead.
func (*TargetField) Descriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_pipeline_proto_rawDescGZIP(), []int{6}
}

func (x *TargetField) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *TargetField) GetType() string {
	if x != nil {
		return x.Type
	}
	return ""
}

func (x *TargetField) GetMutable() bool {
	if x != nil {
		return x.Mutable
	}
	return false
}

func (x *TargetField) GetNullable() bool {
	if x != nil {
		return x.Nullable
	}
	return false
}

func (x *TargetField) GetDescription() string {
	if x != nil {
		return x.Description
	}
	return ""
}

func (x *TargetField) GetPrecision() int32 {
	if x != nil {
		return x.Precision
	}
	return 0
}

func (x *TargetField) GetScale() int32 {
	if x != nil {
		return x.Scale
	}
	return 0
}

// Query defines the SQL transformation logic
type Query struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Reference to the sink alias where results are written
	Target string `protobuf:"bytes,1,opt,name=target,proto3" json:"target,omitempty"`
	// SQL query that transforms source data into target schema
	// This SQL is analyzed to determine execution strategy
	Sql string `protobuf:"bytes,2,opt,name=sql,proto3" json:"sql,omitempty"`
	// Optional: Query type hint (join, aggregation, window, etc.)
	QueryType string `protobuf:"bytes,3,opt,name=query_type,json=queryType,proto3" json:"query_type,omitempty"`
	// Optional: Optimization hints
	Hints         map[string]string `protobuf:"bytes,4,rep,name=hints,proto3" json:"hints,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Query) Reset() {
	*x = Query{}
	mi := &file_datapower_noesis_v1_pipeline_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Query) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Query) ProtoMessage() {}

func (x *Query) ProtoReflect() protoreflect.Message {
	mi := &file_datapower_noesis_v1_pipeline_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Query.ProtoReflect.Descriptor instead.
func (*Query) Descriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_pipeline_proto_rawDescGZIP(), []int{7}
}

func (x *Query) GetTarget() string {
	if x != nil {
		return x.Target
	}
	return ""
}

func (x *Query) GetSql() string {
	if x != nil {
		return x.Sql
	}
	return ""
}

func (x *Query) GetQueryType() string {
	if x != nil {
		return x.QueryType
	}
	return ""
}

func (x *Query) GetHints() map[string]string {
	if x != nil {
		return x.Hints
	}
	return nil
}

// PipelineValidationResult represents the result of pipeline definition validation
type PipelineValidationResult struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Whether validation passed
	Valid bool `protobuf:"varint,1,opt,name=valid,proto3" json:"valid,omitempty"`
	// Validation errors (if any)
	Errors []*PipelineValidationError `protobuf:"bytes,2,rep,name=errors,proto3" json:"errors,omitempty"`
	// Validation warnings (non-blocking issues)
	Warnings      []*PipelineValidationWarning `protobuf:"bytes,3,rep,name=warnings,proto3" json:"warnings,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *PipelineValidationResult) Reset() {
	*x = PipelineValidationResult{}
	mi := &file_datapower_noesis_v1_pipeline_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *PipelineValidationResult) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PipelineValidationResult) ProtoMessage() {}

func (x *PipelineValidationResult) ProtoReflect() protoreflect.Message {
	mi := &file_datapower_noesis_v1_pipeline_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PipelineValidationResult.ProtoReflect.Descriptor instead.
func (*PipelineValidationResult) Descriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_pipeline_proto_rawDescGZIP(), []int{8}
}

func (x *PipelineValidationResult) GetValid() bool {
	if x != nil {
		return x.Valid
	}
	return false
}

func (x *PipelineValidationResult) GetErrors() []*PipelineValidationError {
	if x != nil {
		return x.Errors
	}
	return nil
}

func (x *PipelineValidationResult) GetWarnings() []*PipelineValidationWarning {
	if x != nil {
		return x.Warnings
	}
	return nil
}

type PipelineValidationError struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Error code (e.g., "SCHEMA_MISMATCH", "INVALID_SQL")
	Code string `protobuf:"bytes,1,opt,name=code,proto3" json:"code,omitempty"`
	// Human-readable error message
	Message string `protobuf:"bytes,2,opt,name=message,proto3" json:"message,omitempty"`
	// Location in YAML where error occurred (e.g., "sources[0].schema")
	Location string `protobuf:"bytes,3,opt,name=location,proto3" json:"location,omitempty"`
	// Suggestion for fixing the error
	Suggestion    string `protobuf:"bytes,4,opt,name=suggestion,proto3" json:"suggestion,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *PipelineValidationError) Reset() {
	*x = PipelineValidationError{}
	mi := &file_datapower_noesis_v1_pipeline_proto_msgTypes[9]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *PipelineValidationError) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PipelineValidationError) ProtoMessage() {}

func (x *PipelineValidationError) ProtoReflect() protoreflect.Message {
	mi := &file_datapower_noesis_v1_pipeline_proto_msgTypes[9]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PipelineValidationError.ProtoReflect.Descriptor instead.
func (*PipelineValidationError) Descriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_pipeline_proto_rawDescGZIP(), []int{9}
}

func (x *PipelineValidationError) GetCode() string {
	if x != nil {
		return x.Code
	}
	return ""
}

func (x *PipelineValidationError) GetMessage() string {
	if x != nil {
		return x.Message
	}
	return ""
}

func (x *PipelineValidationError) GetLocation() string {
	if x != nil {
		return x.Location
	}
	return ""
}

func (x *PipelineValidationError) GetSuggestion() string {
	if x != nil {
		return x.Suggestion
	}
	return ""
}

type PipelineValidationWarning struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Warning code
	Code string `protobuf:"bytes,1,opt,name=code,proto3" json:"code,omitempty"`
	// Warning message
	Message string `protobuf:"bytes,2,opt,name=message,proto3" json:"message,omitempty"`
	// Location in YAML
	Location      string `protobuf:"bytes,3,opt,name=location,proto3" json:"location,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *PipelineValidationWarning) Reset() {
	*x = PipelineValidationWarning{}
	mi := &file_datapower_noesis_v1_pipeline_proto_msgTypes[10]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *PipelineValidationWarning) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PipelineValidationWarning) ProtoMessage() {}

func (x *PipelineValidationWarning) ProtoReflect() protoreflect.Message {
	mi := &file_datapower_noesis_v1_pipeline_proto_msgTypes[10]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PipelineValidationWarning.ProtoReflect.Descriptor instead.
func (*PipelineValidationWarning) Descriptor() ([]byte, []int) {
	return file_datapower_noesis_v1_pipeline_proto_rawDescGZIP(), []int{10}
}

func (x *PipelineValidationWarning) GetCode() string {
	if x != nil {
		return x.Code
	}
	return ""
}

func (x *PipelineValidationWarning) GetMessage() string {
	if x != nil {
		return x.Message
	}
	return ""
}

func (x *PipelineValidationWarning) GetLocation() string {
	if x != nil {
		return x.Location
	}
	return ""
}

var File_datapower_noesis_v1_pipeline_proto protoreflect.FileDescriptor

const file_datapower_noesis_v1_pipeline_proto_rawDesc = "" +
	"\n" +
	"\"datapower/noesis/v1/pipeline.proto\x12\x13datapower.noesis.v1\"\xc7\x03\n" +
	"\x12PipelineDefinition\x12#\n" +
	"\rpipeline_name\x18\x01 \x01(\tR\fpipelineName\x12\x1a\n" +
	"\bschedule\x18\x02 \x01(\tR\bschedule\x125\n" +
	"\asources\x18\x03 \x03(\v2\x1b.datapower.noesis.v1.SourceR\asources\x12/\n" +
	"\x05sinks\x18\x04 \x03(\v2\x19.datapower.noesis.v1.SinkR\x05sinks\x12F\n" +
	"\rtarget_schema\x18\x05 \x01(\v2!.datapower.noesis.v1.TargetSchemaR\ftargetSchema\x120\n" +
	"\x05query\x18\x06 \x01(\v2\x1a.datapower.noesis.v1.QueryR\x05query\x12Q\n" +
	"\bmetadata\x18\a \x03(\v25.datapower.noesis.v1.PipelineDefinition.MetadataEntryR\bmetadata\x1a;\n" +
	"\rMetadataEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"\x99\x02\n" +
	"\x06Source\x12\x14\n" +
	"\x05alias\x18\x01 \x01(\tR\x05alias\x123\n" +
	"\x04type\x18\x02 \x01(\x0e2\x1f.datapower.noesis.v1.SourceTypeR\x04type\x12\x12\n" +
	"\x04name\x18\x03 \x01(\tR\x04name\x12O\n" +
	"\x10streaming_source\x18\x04 \x01(\v2$.datapower.noesis.v1.StreamingSourceR\x0fstreamingSource\x128\n" +
	"\x06schema\x18\x05 \x03(\v2 .datapower.noesis.v1.SchemaFieldR\x06schema\x12%\n" +
	"\x0epartition_keys\x18\x06 \x03(\tR\rpartitionKeys\"\x83\x01\n" +
	"\x0fStreamingSource\x12\x12\n" +
	"\x04type\x18\x01 \x01(\tR\x04type\x12\x12\n" +
	"\x04name\x18\x02 \x01(\tR\x04name\x12%\n" +
	"\x0econsumer_group\x18\x03 \x01(\tR\rconsumerGroup\x12!\n" +
	"\fstart_offset\x18\x04 \x01(\tR\vstartOffset\"\xa9\x02\n" +
	"\vSchemaField\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12\x12\n" +
	"\x04type\x18\x02 \x01(\tR\x04type\x12\x1a\n" +
	"\bnullable\x18\x03 \x01(\bR\bnullable\x12#\n" +
	"\rdefault_value\x18\x04 \x01(\tR\fdefaultValue\x12 \n" +
	"\vdescription\x18\x05 \x01(\tR\vdescription\x12\x1c\n" +
	"\tprecision\x18\x06 \x01(\x05R\tprecision\x12\x14\n" +
	"\x05scale\x18\a \x01(\x05R\x05scale\x12!\n" +
	"\felement_type\x18\b \x01(\tR\velementType\x128\n" +
	"\x06fields\x18\t \x03(\v2 .datapower.noesis.v1.SchemaFieldR\x06fields\"\x81\x01\n" +
	"\x04Sink\x12\x14\n" +
	"\x05alias\x18\x01 \x01(\tR\x05alias\x12\x12\n" +
	"\x04type\x18\x02 \x01(\tR\x04type\x12\x12\n" +
	"\x04name\x18\x03 \x01(\tR\x04name\x12#\n" +
	"\rpartition_key\x18\x04 \x01(\tR\fpartitionKey\x12\x16\n" +
	"\x06format\x18\x05 \x01(\tR\x06format\"\xab\x01\n" +
	"\fTargetSchema\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12\x1f\n" +
	"\vprimary_key\x18\x02 \x01(\tR\n" +
	"primaryKey\x128\n" +
	"\x06fields\x18\x03 \x03(\v2 .datapower.noesis.v1.TargetFieldR\x06fields\x12,\n" +
	"\x12primary_key_fields\x18\x04 \x03(\tR\x10primaryKeyFields\"\xc1\x01\n" +
	"\vTargetField\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12\x12\n" +
	"\x04type\x18\x02 \x01(\tR\x04type\x12\x18\n" +
	"\amutable\x18\x03 \x01(\bR\amutable\x12\x1a\n" +
	"\bnullable\x18\x04 \x01(\bR\bnullable\x12 \n" +
	"\vdescription\x18\x05 \x01(\tR\vdescription\x12\x1c\n" +
	"\tprecision\x18\x06 \x01(\x05R\tprecision\x12\x14\n" +
	"\x05scale\x18\a \x01(\x05R\x05scale\"\xc7\x01\n" +
	"\x05Query\x12\x16\n" +
	"\x06target\x18\x01 \x01(\tR\x06target\x12\x10\n" +
	"\x03sql\x18\x02 \x01(\tR\x03sql\x12\x1d\n" +
	"\n" +
	"query_type\x18\x03 \x01(\tR\tqueryType\x12;\n" +
	"\x05hints\x18\x04 \x03(\v2%.datapower.noesis.v1.Query.HintsEntryR\x05hints\x1a8\n" +
	"\n" +
	"HintsEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"\xc2\x01\n" +
	"\x18PipelineValidationResult\x12\x14\n" +
	"\x05valid\x18\x01 \x01(\bR\x05valid\x12D\n" +
	"\x06errors\x18\x02 \x03(\v2,.datapower.noesis.v1.PipelineValidationErrorR\x06errors\x12J\n" +
	"\bwarnings\x18\x03 \x03(\v2..datapower.noesis.v1.PipelineValidationWarningR\bwarnings\"\x83\x01\n" +
	"\x17PipelineValidationError\x12\x12\n" +
	"\x04code\x18\x01 \x01(\tR\x04code\x12\x18\n" +
	"\amessage\x18\x02 \x01(\tR\amessage\x12\x1a\n" +
	"\blocation\x18\x03 \x01(\tR\blocation\x12\x1e\n" +
	"\n" +
	"suggestion\x18\x04 \x01(\tR\n" +
	"suggestion\"e\n" +
	"\x19PipelineValidationWarning\x12\x12\n" +
	"\x04code\x18\x01 \x01(\tR\x04code\x12\x18\n" +
	"\amessage\x18\x02 \x01(\tR\amessage\x12\x1a\n" +
	"\blocation\x18\x03 \x01(\tR\blocation*M\n" +
	"\n" +
	"SourceType\x12\x1b\n" +
	"\x17SOURCE_TYPE_UNSPECIFIED\x10\x00\x12\x11\n" +
	"\rICEBERG_TABLE\x10\x01\x12\x0f\n" +
	"\vKAFKA_TOPIC\x10\x02Bk\n" +
	"\x13datapower.noesis.v1P\x01ZRgithub.com/data-power-io/noesis-protocol/languages/go/datapower/noesis/v1;noesisv1b\x06proto3"

var (
	file_datapower_noesis_v1_pipeline_proto_rawDescOnce sync.Once
	file_datapower_noesis_v1_pipeline_proto_rawDescData []byte
)

func file_datapower_noesis_v1_pipeline_proto_rawDescGZIP() []byte {
	file_datapower_noesis_v1_pipeline_proto_rawDescOnce.Do(func() {
		file_datapower_noesis_v1_pipeline_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_datapower_noesis_v1_pipeline_proto_rawDesc), len(file_datapower_noesis_v1_pipeline_proto_rawDesc)))
	})
	return file_datapower_noesis_v1_pipeline_proto_rawDescData
}

var file_datapower_noesis_v1_pipeline_proto_enumTypes = make([]protoimpl.EnumInfo, 1)
var file_datapower_noesis_v1_pipeline_proto_msgTypes = make([]protoimpl.MessageInfo, 13)
var file_datapower_noesis_v1_pipeline_proto_goTypes = []any{
	(SourceType)(0),                   // 0: datapower.noesis.v1.SourceType
	(*PipelineDefinition)(nil),        // 1: datapower.noesis.v1.PipelineDefinition
	(*Source)(nil),                    // 2: datapower.noesis.v1.Source
	(*StreamingSource)(nil),           // 3: datapower.noesis.v1.StreamingSource
	(*SchemaField)(nil),               // 4: datapower.noesis.v1.SchemaField
	(*Sink)(nil),                      // 5: datapower.noesis.v1.Sink
	(*TargetSchema)(nil),              // 6: datapower.noesis.v1.TargetSchema
	(*TargetField)(nil),               // 7: datapower.noesis.v1.TargetField
	(*Query)(nil),                     // 8: datapower.noesis.v1.Query
	(*PipelineValidationResult)(nil),  // 9: datapower.noesis.v1.PipelineValidationResult
	(*PipelineValidationError)(nil),   // 10: datapower.noesis.v1.PipelineValidationError
	(*PipelineValidationWarning)(nil), // 11: datapower.noesis.v1.PipelineValidationWarning
	nil,                               // 12: datapower.noesis.v1.PipelineDefinition.MetadataEntry
	nil,                               // 13: datapower.noesis.v1.Query.HintsEntry
}
var file_datapower_noesis_v1_pipeline_proto_depIdxs = []int32{
	2,  // 0: datapower.noesis.v1.PipelineDefinition.sources:type_name -> datapower.noesis.v1.Source
	5,  // 1: datapower.noesis.v1.PipelineDefinition.sinks:type_name -> datapower.noesis.v1.Sink
	6,  // 2: datapower.noesis.v1.PipelineDefinition.target_schema:type_name -> datapower.noesis.v1.TargetSchema
	8,  // 3: datapower.noesis.v1.PipelineDefinition.query:type_name -> datapower.noesis.v1.Query
	12, // 4: datapower.noesis.v1.PipelineDefinition.metadata:type_name -> datapower.noesis.v1.PipelineDefinition.MetadataEntry
	0,  // 5: datapower.noesis.v1.Source.type:type_name -> datapower.noesis.v1.SourceType
	3,  // 6: datapower.noesis.v1.Source.streaming_source:type_name -> datapower.noesis.v1.StreamingSource
	4,  // 7: datapower.noesis.v1.Source.schema:type_name -> datapower.noesis.v1.SchemaField
	4,  // 8: datapower.noesis.v1.SchemaField.fields:type_name -> datapower.noesis.v1.SchemaField
	7,  // 9: datapower.noesis.v1.TargetSchema.fields:type_name -> datapower.noesis.v1.TargetField
	13, // 10: datapower.noesis.v1.Query.hints:type_name -> datapower.noesis.v1.Query.HintsEntry
	10, // 11: datapower.noesis.v1.PipelineValidationResult.errors:type_name -> datapower.noesis.v1.PipelineValidationError
	11, // 12: datapower.noesis.v1.PipelineValidationResult.warnings:type_name -> datapower.noesis.v1.PipelineValidationWarning
	13, // [13:13] is the sub-list for method output_type
	13, // [13:13] is the sub-list for method input_type
	13, // [13:13] is the sub-list for extension type_name
	13, // [13:13] is the sub-list for extension extendee
	0,  // [0:13] is the sub-list for field type_name
}

func init() { file_datapower_noesis_v1_pipeline_proto_init() }
func file_datapower_noesis_v1_pipeline_proto_init() {
	if File_datapower_noesis_v1_pipeline_proto != nil {
		return
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_datapower_noesis_v1_pipeline_proto_rawDesc), len(file_datapower_noesis_v1_pipeline_proto_rawDesc)),
			NumEnums:      1,
			NumMessages:   13,
			NumExtensions: 0,
			NumServices:   0,
		},
		GoTypes:           file_datapower_noesis_v1_pipeline_proto_goTypes,
		DependencyIndexes: file_datapower_noesis_v1_pipeline_proto_depIdxs,
		EnumInfos:         file_datapower_noesis_v1_pipeline_proto_enumTypes,
		MessageInfos:      file_datapower_noesis_v1_pipeline_proto_msgTypes,
	}.Build()
	File_datapower_noesis_v1_pipeline_proto = out.File
	file_datapower_noesis_v1_pipeline_proto_goTypes = nil
	file_datapower_noesis_v1_pipeline_proto_depIdxs = nil
}
